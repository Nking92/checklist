{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import pandas as pd\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.expect import Expect\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import INV, MFT\n",
    "from torch.nn import functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = editor.template('{first_name}\\'s favorite sport is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Load pretrained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(tok, mdl, prompt, max_length=150, device='cuda') -> str:\n",
    "    tok_tensor = tok.encode(prompt, return_tensors='pt').to(device) # return_tensors = \"pt\" returns a PyTorch tensor\n",
    "    mdl.eval()\n",
    "    mdl.to(device)\n",
    "    out = mdl.generate(tok_tensor, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, output_scores=True, return_dict_in_generate=True)\n",
    "    text = tok.decode(out.sequences[0], skip_special_tokens=True)\n",
    "    scores = out.scores[0]\n",
    "    return {\"text\": text, \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'hello.com/news/local/michigan-county-police-officer-involved-in-suspicious-vehicle-crash.html',\n",
       " 'scores': tensor([[-5.7012e+00, -5.1147e+00, -8.9818e+00,  ..., -1.5148e+01,\n",
       "          -1.4048e+01, -6.5405e+00],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09]], device='cuda:0')}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(tokenizer, model, 'hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token(tokenizer, model, prompt, top_k=5, device='cuda'):\n",
    "    prompt = prompt.strip()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    input_tokenized_length = input_ids.size(1)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids, \n",
    "        max_length=(input_tokenized_length + 1), \n",
    "        num_beams=top_k, \n",
    "        num_return_sequences=top_k, \n",
    "        early_stopping=True,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True\n",
    "    )\n",
    "\n",
    "    sequence_probabilities = F.softmax(beam_outputs.sequences_scores, dim=0)\n",
    "    \n",
    "    token_scores = []\n",
    "    for i, beam_output in enumerate(beam_outputs.sequences):\n",
    "        sequence_score = sequence_probabilities[i].item()\n",
    "        decoded_sequence = tokenizer.decode(beam_output, skip_special_tokens=True)\n",
    "        new_token = decoded_sequence[len(prompt):]\n",
    "        token_scores.append((new_token, sequence_score))\n",
    "    \n",
    "    return token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' lawyer', 0.21111242473125458),\n",
       " (' writer', 0.2087818831205368),\n",
       " (' consultant', 0.20089176297187805),\n",
       " (' journalist', 0.19572344422340393),\n",
       " (' freelance', 0.18349044024944305)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_token(tokenizer, model, \"John works as a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invariant_next_token_test(strs):\n",
    "    # first pass\n",
    "    all_predicted_tokens = set()\n",
    "    for s in strs:\n",
    "        token_probabilities = predict_next_token(tokenizer, model, s)\n",
    "        for prediction in token_probabilities:\n",
    "            all_predicted_tokens.add(prediction[0])\n",
    "\n",
    "    print(\"Predictions:\", all_predicted_tokens)\n",
    "\n",
    "    passed = []\n",
    "    failed = []\n",
    "\n",
    "    # second pass\n",
    "    for s in strs:\n",
    "        token_probabilities = predict_next_token(tokenizer, model, s)\n",
    "        predicted = set()\n",
    "        for prediction in token_probabilities:\n",
    "            predicted.add(prediction[0])\n",
    "        if predicted == all_predicted_tokens:\n",
    "            passed.append(s)\n",
    "        else:\n",
    "            failed.append(s)\n",
    "\n",
    "    print(f\"Pass: {len(passed)/len(strs)*100}%\")\n",
    "    print(f\"Fail: {len(failed)/len(strs)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' writer', ' nurse', ' lawyer', ' doctor', ' professor', ' consultant', ' journalist', ' freelance', ' teacher', ' waitress'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('{first_name} works as a')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' Margaret', ' Well', ' She', ' Robert', ' It', ' Susan', ' He', ' How', ' Is', ' What', ' James', ' I', ' Mary', '\\n', ' The'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('What is {first_name}\\'s profession?')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' Well', ' She', ' He', ' How', ' Is', ' What', '\\n'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('What does {first_name} do for a living?')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' She', '\\n\\n', ' He', ' How', ' Is', ' What', ' I', '\\n', ' ('}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('Where is {first_name} from?')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' She', ' Her', ' It', ' He', ' \"', ' I', '\\n', ' (', ' The'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('What is {first_name}\\'s favorite food?')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' his', ' rice', ' the', ' Japanese', ' her', ' sushi', ' a'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('After living in Japan for 25 years, {first_name}\\'s favorite food is ')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' State', ' states', ' Kingdom', ' Arab', ' Nations', ' States'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('The state of {state} is located in the United ', state=['Delaware', 'Tennessee', 'Georgia', 'Washington', 'Oregon', 'California', 'New Mexico', 'Alaska', 'Hawaii', 'Colorado'])\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(inputs):\n",
    "    responses = []\n",
    "    confidences = []\n",
    "    for prompt in inputs:\n",
    "        predictions = predict_next_token(tokenizer, model, prompt, device='cuda')\n",
    "        next_tokens = []\n",
    "        token_confidences = []\n",
    "        for pred in predictions:\n",
    "            next_tokens.append(pred[0])\n",
    "            token_confidences.append(pred[1])\n",
    "        responses.append(next_tokens)\n",
    "        confidences.append(token_confidences)\n",
    "    return (responses, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[' States', ' Kingdom', ' State', ' states', ' Nations'],\n",
       "  [' States', ' Kingdom', ' State', ' states', ' Nations']],\n",
       " [[0.29671230912208557,\n",
       "   0.23459471762180328,\n",
       "   0.16363166272640228,\n",
       "   0.152780219912529,\n",
       "   0.15228109061717987],\n",
       "  [0.316251665353775,\n",
       "   0.1981416791677475,\n",
       "   0.1675654500722885,\n",
       "   0.15963605046272278,\n",
       "   0.158405140042305]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_test_predictions(prompts.data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expect_fn():\n",
    "    seen_tokens = set()\n",
    "    def e_fn(x, pred, conf, label=None, meta=None, run_idxs=None):\n",
    "        print(\"x\\t\\t\", x)\n",
    "        print(\"pred\\t\\t\", pred)\n",
    "        print(\"conf\\t\\t\", conf)\n",
    "        results = []\n",
    "        for p in pred:\n",
    "            for token in p:\n",
    "                seen_tokens.add(token)\n",
    "        for p in pred:\n",
    "            example_tokens = set()\n",
    "            for token in p:\n",
    "                example_tokens.add(token)\n",
    "            results.append([example_tokens == seen_tokens])\n",
    "        return results\n",
    "    return Expect.test(e_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect = make_expect_fn()\n",
    "test = MFT(**prompts, name='Next token invariant', description='The next predicted token is invariant for each prompt', expect=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n",
      "x\t\t ['The state of Delaware is located in the United ', 'The state of Tennessee is located in the United ', 'The state of Georgia is located in the United ', 'The state of Washington is located in the United ', 'The state of Oregon is located in the United ', 'The state of California is located in the United ', 'The state of New Mexico is located in the United ', 'The state of Alaska is located in the United ', 'The state of Hawaii is located in the United ', 'The state of Colorado is located in the United ']\n",
      "pred\t\t [[' States', ' Kingdom', ' State', ' states', ' Nations'], [' States', ' Kingdom', ' State', ' states', ' Nations'], [' States', ' Kingdom', ' Nations', ' State', ' states'], [' States', ' Kingdom', ' Nations', ' State', ' states'], [' States', ' Kingdom', ' State', ' Nations', ' states'], [' States', ' Kingdom', ' State', ' states', ' Arab'], [' States', ' Kingdom', ' State', ' states', ' Nations'], [' States', ' Kingdom', ' State', ' Nations', ' states'], [' States', ' Kingdom', ' Nations', ' State', ' Arab'], [' States', ' Kingdom', ' State', ' states', ' Nations']]\n",
      "conf\t\t [[0.29671230912208557, 0.23459471762180328, 0.16363166272640228, 0.152780219912529, 0.15228109061717987], [0.316251665353775, 0.1981416791677475, 0.1675654500722885, 0.15963605046272278, 0.158405140042305], [0.3111943304538727, 0.1939479261636734, 0.16944719851016998, 0.16580753028392792, 0.15960299968719482], [0.3086817264556885, 0.20875276625156403, 0.16656894981861115, 0.16171573102474213, 0.15428079664707184], [0.3192470371723175, 0.20142240822315216, 0.16737723350524902, 0.15733177959918976, 0.15462160110473633], [0.31255823373794556, 0.20376038551330566, 0.16429877281188965, 0.16090480983257294, 0.15847772359848022], [0.3076719045639038, 0.18157145380973816, 0.1754608303308487, 0.17235246300697327, 0.16294337809085846], [0.3286248743534088, 0.19237354397773743, 0.16374646127223969, 0.15909840166568756, 0.15615667402744293], [0.32350364327430725, 0.18780860304832458, 0.16901344060897827, 0.16242149472236633, 0.15725284814834595], [0.3166036903858185, 0.20368371903896332, 0.16476140916347504, 0.158112570643425, 0.1568385809659958]]\n"
     ]
    }
   ],
   "source": [
    "test.run(generate_test_predictions, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[' States', ' Kingdom', ' State', ' Nations', ' states'] The state of Alaska is located in the United \n",
      "\n",
      "----\n",
      "[' States', ' Kingdom', ' State', ' states', ' Arab'] The state of California is located in the United \n",
      "\n",
      "----\n",
      "[' States', ' Kingdom', ' State', ' states', ' Nations'] The state of Delaware is located in the United \n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669591e07d7c42b3a8ee5e64d5375ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TestSummarizer(stats={'npassed': 0, 'nfailed': 10, 'nfiltered': 0}, summarizer={'name': 'Next token invariant'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.visual_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
