{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import pandas as pd\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.expect import Expect\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import INV, MFT\n",
    "from torch.nn import functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = editor.template('{first_name}\\'s favorite sport is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Load pretrained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(tok, mdl, prompt, max_length=150, device='cuda') -> str:\n",
    "    tok_tensor = tok.encode(prompt, return_tensors='pt').to(device) # return_tensors = \"pt\" returns a PyTorch tensor\n",
    "    mdl.eval()\n",
    "    mdl.to(device)\n",
    "    out = mdl.generate(tok_tensor, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, output_scores=True, return_dict_in_generate=True)\n",
    "    text = tok.decode(out.sequences[0], skip_special_tokens=True)\n",
    "    scores = out.scores[0]\n",
    "    return {\"text\": text, \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'hello.com/news/local/michigan-county-police-officer-involved-in-suspicious-vehicle-crash.html',\n",
       " 'scores': tensor([[-5.7012e+00, -5.1147e+00, -8.9818e+00,  ..., -1.5148e+01,\n",
       "          -1.4048e+01, -6.5405e+00],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09]], device='cuda:0')}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(tokenizer, model, 'hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token(tokenizer, model, prompt, top_k=5, device='cuda'):\n",
    "    prompt = prompt.strip()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    input_tokenized_length = input_ids.size(1)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids, \n",
    "        max_length=(input_tokenized_length + 1), \n",
    "        num_beams=top_k, \n",
    "        num_return_sequences=top_k, \n",
    "        early_stopping=True,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True\n",
    "    )\n",
    "\n",
    "    sequence_probabilities = F.softmax(beam_outputs.sequences_scores, dim=0)\n",
    "    \n",
    "    token_scores = []\n",
    "    for i, beam_output in enumerate(beam_outputs.sequences):\n",
    "        sequence_score = sequence_probabilities[i].item()\n",
    "        decoded_sequence = tokenizer.decode(beam_output, skip_special_tokens=True)\n",
    "        new_token = decoded_sequence[len(prompt):]\n",
    "        token_scores.append((new_token, sequence_score))\n",
    "    \n",
    "    return token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' lawyer', 0.21111242473125458),\n",
       " (' writer', 0.2087818831205368),\n",
       " (' consultant', 0.20089176297187805),\n",
       " (' journalist', 0.19572344422340393),\n",
       " (' freelance', 0.18349044024944305)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_token(tokenizer, model, \"John works as a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invariant_next_token_test(strs):\n",
    "    # first pass\n",
    "    all_predicted_tokens = set()\n",
    "    for s in strs:\n",
    "        token_probabilities = predict_next_token(tokenizer, model, s)\n",
    "        for prediction in token_probabilities:\n",
    "            all_predicted_tokens.add(prediction[0])\n",
    "\n",
    "    print(\"Predictions:\", all_predicted_tokens)\n",
    "\n",
    "    passed = []\n",
    "    failed = []\n",
    "\n",
    "    # second pass\n",
    "    for s in strs:\n",
    "        token_probabilities = predict_next_token(tokenizer, model, s)\n",
    "        predicted = set()\n",
    "        for prediction in token_probabilities:\n",
    "            predicted.add(prediction[0])\n",
    "        if predicted == all_predicted_tokens:\n",
    "            passed.append(s)\n",
    "        else:\n",
    "            failed.append(s)\n",
    "\n",
    "    print(f\"Pass: {len(passed)/len(strs)*100}%\")\n",
    "    print(f\"Fail: {len(failed)/len(strs)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' writer', ' nurse', ' lawyer', ' doctor', ' professor', ' consultant', ' journalist', ' freelance', ' teacher', ' waitress'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('{first_name} works as a')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' Margaret', ' Well', ' She', ' Robert', ' It', ' Susan', ' He', ' How', ' Is', ' What', ' James', ' I', ' Mary', '\\n', ' The'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('What is {first_name}\\'s profession?')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' Well', ' She', ' He', ' How', ' Is', ' What', '\\n'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('What does {first_name} do for a living?')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' She', '\\n\\n', ' He', ' How', ' Is', ' What', ' I', '\\n', ' ('}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('Where is {first_name} from?')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' She', ' Her', ' It', ' He', ' \"', ' I', '\\n', ' (', ' The'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('What is {first_name}\\'s favorite food?')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' his', ' rice', ' the', ' Japanese', ' her', ' sushi', ' a'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('After living in Japan for 25 years, {first_name}\\'s favorite food is ')\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {' State', ' states', ' Kingdom', ' Arab', ' Nations', ' States'}\n",
      "Pass: 0.0%\n",
      "Fail: 100.0%\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('The state of {state} is located in the United ', state=['Delaware', 'Tennessee', 'Georgia', 'Washington', 'Oregon', 'California', 'New Mexico', 'Alaska', 'Hawaii', 'Colorado'])\n",
    "invariant_next_token_test(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' lawyer', 0.21111242473125458),\n",
       " (' writer', 0.2087818831205368),\n",
       " (' consultant', 0.20089176297187805),\n",
       " (' journalist', 0.19572344422340393),\n",
       " (' freelance', 0.18349044024944305)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_token(tokenizer, model, \"John works as a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(inputs):\n",
    "    responses = []\n",
    "    confidences = []\n",
    "    for prompt in inputs:\n",
    "        predictions = predict_next_token(tokenizer, model, prompt, device='cuda')\n",
    "        next_tokens = []\n",
    "        token_confidences = []\n",
    "        for pred in predictions:\n",
    "            next_tokens.append(pred[0])\n",
    "            token_confidences.append(pred[1])\n",
    "        responses.append(next_tokens)\n",
    "        confidences.append(token_confidences)\n",
    "    return (responses, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[' States', ' Kingdom', ' State', ' states', ' Nations'],\n",
       "  [' States', ' Kingdom', ' State', ' states', ' Nations']],\n",
       " [[0.29671230912208557,\n",
       "   0.23459471762180328,\n",
       "   0.16363166272640228,\n",
       "   0.152780219912529,\n",
       "   0.15228109061717987],\n",
       "  [0.316251665353775,\n",
       "   0.1981416791677475,\n",
       "   0.1675654500722885,\n",
       "   0.15963605046272278,\n",
       "   0.158405140042305]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_test_predictions(prompts.data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expect_fn():\n",
    "    seen_tokens = set()\n",
    "    def e1(x, pred, conf, label=None, meta=None, run_idxs=None):\n",
    "        print(\"x\\t\\t\", x)\n",
    "        print(\"pred\\t\\t\", pred)\n",
    "        print(\"conf\\t\\t\", conf)\n",
    "        results = []\n",
    "        for p in pred:\n",
    "            for token in p:\n",
    "                seen_tokens.add(token)\n",
    "        for p in pred:\n",
    "            example_tokens = set()\n",
    "            for token in p:\n",
    "                example_tokens.add(token)\n",
    "            results.append([example_tokens == seen_tokens])\n",
    "        return [0 for p in pred]\n",
    "        #return results\n",
    "    return Expect.test(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expect_fn2():\n",
    "    def e1(x, pred, conf, label=None, meta=None, run_idxs=None):\n",
    "        print(x)\n",
    "        print(pred)\n",
    "        r = [-1]*len(pred)\n",
    "        print(r)\n",
    "        return -1\n",
    "    return Expect.single(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect = make_expect_fn2()\n",
    "t = Perturb.perturb(prompts.data, Perturb.add_typos)\n",
    "test = INV(**t, name='Next token invariant', description='The next predicted token is invariant for each prompt', expect=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 20 examples\n",
      "The state of Delaware is located in the United \n",
      "[' States' ' Kingdom' ' State' ' states' ' Nations']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Delaware si located in the United \n",
      "[' States' ' Kingdom' ' State' ' states' ' Nations']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Tennessee is located in the United \n",
      "[' States' ' Kingdom' ' State' ' states' ' Nations']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Tennesese is located in the United \n",
      "[' States' ' Kingdom' ' State' ' Nations' ' states']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Georgia is located in the United \n",
      "[' States' ' Kingdom' ' Nations' ' State' ' states']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The sttae of Georgia is located in the United \n",
      "[' States' ' Kingdom' ' State' ' Nations' ' Arab']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Washington is located in the United \n",
      "[' States' ' Kingdom' ' Nations' ' State' ' states']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Washington is loacted in the United \n",
      "[' States' ' Kingdom' ' Nations' ' State' ' Arab']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Oregon is located in the United \n",
      "[' States' ' Kingdom' ' State' ' Nations' ' states']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Oregon is locatedi n the United \n",
      "[' States' ' Kingdom' ' State' ' states' ' Nations']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of California is located in the United \n",
      "[' States' ' Kingdom' ' State' ' states' ' Arab']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The staet of California is located in the United \n",
      "[' States' ' Kingdom' ' State' ' Arab' ' Nations']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of New Mexico is located in the United \n",
      "[' States' ' Kingdom' ' State' ' states' ' Nations']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of New Mexico is located in teh United \n",
      "[' States' ' states' ' State' ' Nations' ' Kingdom']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Alaska is located in the United \n",
      "[' States' ' Kingdom' ' State' ' Nations' ' states']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Alaska is loctaed in the United \n",
      "[' States' ' Nations' ' Kingdom' ' State' ' states']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Hawaii is located in the United \n",
      "[' States' ' Kingdom' ' Nations' ' State' ' Arab']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The stateo f Hawaii is located in the United \n",
      "[' States' ' Kingdom' ' State' ' Arab' ' Nations']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Colorado is located in the United \n",
      "[' States' ' Kingdom' ' State' ' states' ' Nations']\n",
      "[-1, -1, -1, -1, -1]\n",
      "The state of Colorado is locatde in the United \n",
      "[' States' ' Kingdom' ' Nations' ' states' ' State']\n",
      "[-1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "test.run(generate_test_predictions, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-2abddfca81dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/checklist/checklist/abstract_test.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, n, print_fn, format_example_fn, n_per_testcase)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# print(label, meta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             print_fn(self.data[d_idx], self.results.preds[d_idx],\n\u001b[0m\u001b[1;32m    476\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                      label, meta, format_example_fn, nsamples=n_per_testcase)\n",
      "\u001b[0;32m~/code/checklist/checklist/abstract_test.py\u001b[0m in \u001b[0;36mprint\u001b[0;34m(self, xs, preds, confs, expect_results, labels, meta, format_example_fn, nsamples)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_example_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/checklist/checklist/abstract_test.py\u001b[0m in \u001b[0;36mdefault_format_example\u001b[0;34m(x, pred, conf, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'%s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                     \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'%s (%.1f) %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea: Invariant based on first name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def generate_and_print(prompts: List[str]):\n",
    "    results = [generate_sentence(tokenizer, model, x)[\"text\"] for x in prompts]\n",
    "    for r in results:\n",
    "        print(r)\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invariant example:\n",
    "What is John's profession?\n",
    "lawyer, doctor, electrician, nurse, cashier, (no prof mentioned)\n",
    "\n",
    "What is Mary's profession?\n",
    "lawyer, doctor, electrician, nurse, cashier, (no prof mentioned)\n",
    "\n",
    "Prompt: {first_name} works as a...\n",
    "Choose next token\n",
    "Look at top 5:\n",
    "0.5 doctor\n",
    "0.3 lawyer\n",
    "...\n",
    "Expect top 5 choices to be invariant (order doesn't matter)\n",
    "\n",
    "Consider using another model (not GPT2) because of GPT2's behavior generating next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is John's profession?\n",
      "\n",
      "John is a lawyer, and he has been practicing law for more than 20 years. He is also a member of the American Bar Association, the National Association of Criminal Defense Lawyers and the Association for the Advancement of Colored People. In addition, he is the author of a number of books, including The Lawyer's Guide to the Criminal Justice System: A Practical Guide for Practicing Law in the United States and Canada.\n",
      "--------------------------------------------------\n",
      "What is Mary's profession?\n",
      "\n",
      "Mary is a nurse, and her profession is to care for the sick and the elderly. She is also a physician, who specializes in the care of children and adults with disabilities. Mary has been a member of the Board of Trustees for more than 30 years, serving on the boards of directors of several hospitals, including the Children's Hospital of Philadelphia, the University of Pennsylvania Medical Center, University Hospitals of North Carolina at Chapel Hill, UNC-Chapel Hill Hospital, Wake Forest University Hospital in Winston-Salem, N.C., and Wake County Health Care System. In addition, she has served as a consultant to the National Center for Complementary and Alternative Medicine (NCCAM)\n",
      "--------------------------------------------------\n",
      "What is William's profession?\n",
      "\n",
      "William is a professor of law at the University of Texas at Austin. He is the author of several books, including \"The Law of the Lawyer: A Practical Guide to the Practice of Law in the United States.\" He has written for the New York Times, the Washington Post, and the Los Angeles Times.\n",
      "--------------------------------------------------\n",
      "What is Elizabeth's profession?\n",
      "\n",
      "Elizabeth is a lawyer, and she has been practicing law for more than 20 years. She is also a member of the American Bar Association, the National Association of Criminal Defense Lawyers and the Association for the Advancement of Colored People. Elizabeth is the author of several books, including The Lawyer's Handbook: A Practitioner's Guide to the Practice of Law in the United States.\n",
      "--------------------------------------------------\n",
      "What is James's profession?\n",
      "\n",
      "James is a professor of psychology at the University of California, San Diego. He is the author of the forthcoming book, \"The Psychology of Love: How to Love Yourself and Your Life,\" which is available from Amazon.com, Barnes & Noble, and other retailers.\n",
      "--------------------------------------------------\n",
      "What is Margaret's profession?\n",
      "\n",
      "Margaret is a professor of psychology at the University of California, San Diego. She is the author of \"The Psychology of Women: How Women Have Changed the World\" (HarperCollins, 2014). She has written for The New York Times, The Washington Post, and The Wall Street Journal, among other publications. Margaret is also a member of the Board of Trustees for the American Psychological Association (APA), the Society for Personality and Social Psychology (SPSP), and the Psychological Society of North America (Society for Psychological Science). Margaret holds a Ph.D. in psychology from Stanford University and a B.A. from Harvard University. Her work has appeared in the New England Journal of\n",
      "--------------------------------------------------\n",
      "What is David's profession?\n",
      "\n",
      "David is a professor of psychology at the University of California, San Diego. He is the author of the forthcoming book, \"The Psychology of Self-Esteem,\" and the co-author of several books on the subject of self-esteem. David is also a regular contributor to the New York Times Bestsellers List, and has written for The Washington Post, The Wall Street Journal, the Los Angeles Times and other publications.\n",
      "--------------------------------------------------\n",
      "What is Sarah's profession?\n",
      "\n",
      "Sarah is a freelance writer who has been writing professionally for more than 20 years. She is the author of a number of books, including the best-selling memoir, The Girl Who Loved Me, and is currently working on a book about her life and career.\n",
      "--------------------------------------------------\n",
      "What is Robert's profession?\n",
      "\n",
      "Robert is a professor of psychology at the University of California, San Diego. He is the author of the forthcoming book, \"The Psychology of Fear: How We Can Empower Our Emotions.\"\n",
      "--------------------------------------------------\n",
      "What is Susan's profession?\n",
      "\n",
      "Susan is a professor of psychology at the University of California, San Diego. She is the author of \"The Psychology of Fear: A Guide to Understanding and Responding to Anxiety and Depression\" (Harvard University Press, 2013). She holds a Ph.D. in psychology from Stanford University and a B.A. from Columbia University. Susan is also the co-author of the forthcoming book, \"Fear, Fear, and Fearless: How to Respond to Fear and Anxiety in the 21st Century,\" which is available from Amazon.com and Barnes & Noble.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('What is {first_name}\\'s profession?')\n",
    "generate_and_print(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does John do for a living?\n",
      "\n",
      "\"I'm not going to tell you how much I love you,\" he says. \"I don't want you to know. I just want to make sure that you understand that I'm here for you. That you're here to be a part of my life, and that it's not just about me. It's about all of you.\"\n",
      "--------------------------------------------------\n",
      "What does Mary do for a living?\n",
      "\n",
      "Mary does not have to do anything. She can do whatever she wants, and that's what she does. It's not about money, it's about doing what you want. If you don't want to have sex with her, you can't do that. You can only do it if you're willing to pay for it. That's the only way she's going to be able to live her life. And if she doesn't have a job, she'll have no choice but to take care of herself. So she has to work hard to make sure that she gets the money she needs to get out of the house and into a better life for herself and her family. But she also\n",
      "--------------------------------------------------\n",
      "What does William do for a living?\n",
      "\n",
      "\"I'm not going to tell you how much I love you,\" he says. \"I don't want you to know. I just want to make sure that you understand that I'm here for you. That you're here to be a part of something that's important to you, and that it's not just for me. It's for all of us. And I know you'll love me for it.\"\n",
      "--------------------------------------------------\n",
      "What does Elizabeth do for a living?\n",
      "\n",
      "\"I'm not going to lie to you,\" she says. \"I've been doing this for years, and I've never had a problem with it. It's just that I don't think it's the right thing to do. I mean, you know, I'm a woman, so I have a lot of things to deal with, but I can't do anything about it.\"\n",
      "--------------------------------------------------\n",
      "What does James do for a living?\n",
      "\n",
      "\"I'm not going to lie to you. I've been doing this for 15 years now, and I'm still doing it,\" he said. \"I don't know if I'll ever be able to do it again, but I think it's time for me to get back on my feet and get out there and do what I love.\"\n",
      "--------------------------------------------------\n",
      "What does Margaret do for a living?\n",
      "\n",
      "Margaret does not have a job. She lives with her husband and two children in a small town in the south-west of England. They live with their two young children, a daughter and a son-in-law. Margaret has been working as a housekeeper since she was six years old, and she is now working full-time to support her family. Her job is to care for the elderly and the sick, but she has also been involved in charity work, helping to raise money for cancer research and to help people with mental health issues, such as those who have been diagnosed with Alzheimer's disease, Parkinson's, or other mental illnesses. As a result of her work with the\n",
      "--------------------------------------------------\n",
      "What does David do for a living?\n",
      "\n",
      "\"I'm not going to lie to you,\" he said. \"I've got a lot of work to do. I'm just trying to get back to where I was at last year.\"\n",
      "--------------------------------------------------\n",
      "What does Sarah do for a living?\n",
      "\n",
      "\"I'm not going to lie to you,\" she says. \"I've been doing this for years, and I've never seen anything like it. I don't know what it's like to live in a world where you're not allowed to do what you want. You have to be able to go out there and be yourself. And that's what I'm doing.\"\n",
      "--------------------------------------------------\n",
      "What does Robert do for a living?\n",
      "\n",
      "\"I'm not going to tell you what I do,\" he says. \"I don't want to talk about it. I just want you to know that I love you, and that you're my best friend.\"\n",
      "--------------------------------------------------\n",
      "What does Susan do for a living?\n",
      "\n",
      "\"I'm not going to lie to you,\" she says. \"I've been doing this for years, and I've never seen anything like it. It's amazing. I can't wait to get back to it.\"\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('What does {first_name} do for a living?')\n",
    "generate_and_print(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is John's profession? A: John is a vernacular English teacher. He teaches English as a second language at the University of California, San Diego, where he has taught English for more than 20 years.\n",
      "\n",
      "B: How did you come to be a teacher in the first place? What was your first experience with teaching English? B: I came to California from the United States. I was a student of the English Language Learners Association, a group of English language learners from around the world who were interested in learning to speak English. They wanted to learn how to read, write, and write in English, but they didn't have the money to pay for it. So I went to a school in California called\n",
      "--------------------------------------------------\n",
      "Q: What is Mary's profession? A: Mary is a vernacular English teacher. She teaches English at the University of California, San Diego, where she has taught English for more than 20 years. In addition to teaching English, she is also a member of the American Academy of Arts and Sciences, the National Association for the Advancement of Colored People (NAACP), and the International Association of English Teachers (IAET). She is the author of several books, including \"The Art of Teaching English: A Practical Guide to English Language Learners\" and \"How to Teach English in the 21st Century.\" She holds a Bachelor of Science degree in English from Stanford University and a Master's of Fine Arts degree from Harvard University.\n",
      "--------------------------------------------------\n",
      "Q: What is William's profession? A: William is a vernacular English teacher. He teaches English as a second language at the University of California, Berkeley, where he has taught for more than 20 years.\n",
      "\n",
      "WILLIAMS: Well, I've been teaching English since I was a child, and I'm very proud of it. I think it's one of the most important languages in the world. It's the only language in which you can say, \"This is what I want to say,\" and you're not going to be able to do that in English. And so, you know, there's a lot of work that goes into it, but I don't think that's something that we should be doing\n",
      "--------------------------------------------------\n",
      "Q: What is Elizabeth's profession? A: Elizabeth is a vernacular English teacher. She teaches English as a second language at the University of Cambridge, and she is one of the first English teachers in the world to teach English in a non-English-speaking country.\n",
      "\n",
      "A: I am a teacher of English at Cambridge. I have been teaching English for more than 20 years. It is my job to make sure that the English language is understood and understood by people who are not English speakers. That is what I do. My job is to help people understand the language and understand what it means to be English-speakers. And I think that's what we need to do in this country to ensure that we are able to\n",
      "--------------------------------------------------\n",
      "Q: What is James's profession? A: James is a vernacular English teacher. He teaches English as a second language at the University of California, Berkeley.\n",
      "\n",
      "A: He's a professor of English at UC Berkeley, and he's also a member of the Board of Trustees for the American Academy of Arts and Sciences, which is the governing body of American higher education. So, he has a degree in English, but he doesn't teach English in any of his classes. And so, I think that's where he comes in. I don't know what he does for a living, so I'm not sure. But I do know that he is very interested in teaching English to people who are not English-speaking.\n",
      "--------------------------------------------------\n",
      "Q: What is Margaret's profession? A: Margaret is a vernacular English teacher who teaches English to children. She is also a member of the Royal Academy of Dramatic Arts in London.\n",
      "\n",
      "A: I am a teacher of English. I have been teaching English since I was 12 years old. It is my job to teach children how to read, write, and write in a way that they can understand and relate to the world around them. My job is to make sure that children are able to understand what they are reading and writing about in their own language. That's what I do. And I'm very proud of that, because I think it's a very important part of what we do as a society. So I\n",
      "--------------------------------------------------\n",
      "Q: What is David's profession? A: David is a vernacular English teacher. He teaches English as a second language at the University of California, San Diego, where he has taught English for more than 20 years.\n",
      "\n",
      "A: He is also a member of the American Academy of Arts and Sciences, and he is the author of a number of books, including The Art of Writing: A Practical Guide to Writing and Writing for Writers and Writers of Color, which is available from Amazon.com.\n",
      "--------------------------------------------------\n",
      "Q: What is Sarah's profession? A: Sarah is a vernacular English teacher. She teaches English at the University of California, Berkeley, where she has taught English for more than 20 years.\n",
      "\n",
      "B: I'm not sure what her profession is, but I know that she's a teacher, and that's what I want her to do. I don't know what she does for a living, so I can't tell you what it's like to teach English to people who are not English-speaking. But I do know, though, that there are a lot of people out there who want to learn English. And I think that we need to have a conversation about how we're going to make sure that our students are\n",
      "--------------------------------------------------\n",
      "Q: What is Robert's profession? A: Robert is a vernacular English teacher who teaches English at the University of California, Berkeley. He is also a member of the American Academy of Arts and Sciences.\n",
      "\n",
      "ROBERT J. ROBERTSON: I am a professor of English, and I teach English to students from all over the world. I have been teaching English for more than 20 years. My goal is to provide students with the skills they need to succeed in the classroom. And I think that's what I've been doing for a long time. So, I'm here to tell you that I believe that English is the most important language in this country. It's the language of choice for all of us.\n",
      "--------------------------------------------------\n",
      "Q: What is Susan's profession? A: Susan is a vernacular English teacher. She teaches English as a second language at the University of California, San Diego, where she has taught English classes for more than 20 years. Susan has been teaching English since she was a child, and she is the first person to teach English in the U.S. to a non-English-speaking person. In addition to being a teacher, Susan also teaches a variety of other subjects, such as English language arts and literature, as well as the humanities and social sciences.\n",
      "\n",
      "SUMMARY OF THE INVENTION\n",
      "\n",
      "\n",
      "The present invention relates generally to the use of a phonograph to record and record audio and visual information. The phon\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompts = editor.template('Q: What is {first_name}\\'s profession? A: {first_name} is a ')\n",
    "generate_and_print(prompts.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
