{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import pandas as pd\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.expect import Expect\n",
    "from checklist.test_types import MFT\n",
    "from torch.nn import functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# Load pretrained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dog is running in the zoo',\n",
       " 'The cat is running in the zoo',\n",
       " 'The giraffe is running in the zoo',\n",
       " 'The aardvark is running in the zoo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = Editor()\n",
    "animal_prompts = editor.template(\"The {animal} is running in the zoo\", animal=[\"dog\", \"cat\", \"giraffe\", \"aardvark\"], meta=True)\n",
    "animal_prompts.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_animal(x, pred, conf, label=None, meta=None):\n",
    "    return meta['animal'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_animal_expect_fn = Expect.single(contains_same_animal)\n",
    "same_animal_test = MFT(**animal_prompts, name='Same animal in response', description='The response contains the same animal mentioned in the prompt.', expect=same_animal_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'meta': [{'country': 'Angola'}, {'country': 'Federated States of Micronesia'}, {'country': 'Pakistan'}, {'country': 'Benin'}, {'country': 'Dominica'}, {'country': 'Kyrgyzstan'}, {'country': 'Egypt'}, {'country': 'South Korea'}, {'country': 'Turkey'}, {'country': 'Moldova'}], 'data': ['I want to travel to Angola next year.', 'I want to travel to Federated States of Micronesia next year.', 'I want to travel to Pakistan next year.', 'I want to travel to Benin next year.', 'I want to travel to Dominica next year.', 'I want to travel to Kyrgyzstan next year.', 'I want to travel to Egypt next year.', 'I want to travel to South Korea next year.', 'I want to travel to Turkey next year.', 'I want to travel to Moldova next year.']})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_prompts = editor.template(\"I want to travel to {country} next year.\", meta=True, nsamples=10)\n",
    "country_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_country(x, pred, conf, label=None, meta=None):\n",
    "    return meta['country'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_country_expect_fn = Expect.single(contains_same_country)\n",
    "same_country_test = MFT(**country_prompts, name='Same country in response', description='The response contains the same country mentioned in the prompt.', expect=same_country_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'meta': [{'first_name': 'Charlie'}, {'first_name': 'Dan'}, {'first_name': 'Ron'}, {'first_name': 'Jay'}, {'first_name': 'Thomas'}, {'first_name': 'Katie'}, {'first_name': 'Benjamin'}, {'first_name': 'Johnny'}, {'first_name': 'Virginia'}, {'first_name': 'Helen'}], 'data': ['Charlie is my best friend.', 'Dan is my best friend.', 'Ron is my best friend.', 'Jay is my best friend.', 'Thomas is my best friend.', 'Katie is my best friend.', 'Benjamin is my best friend.', 'Johnny is my best friend.', 'Virginia is my best friend.', 'Helen is my best friend.']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_prompts = editor.template(\"{first_name} is my best friend.\", meta=True, nsamples=10)\n",
    "person_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_person(x, pred, conf, label=None, meta=None):\n",
    "    return meta['first_name'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_person_expect_fn = Expect.single(contains_same_person)\n",
    "same_person_test = MFT(**person_prompts, name='Same person in response', description='The response contains the same person mentioned in the prompt.', expect=same_person_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(tok, mdl, prompt, max_length=150, device='cuda') -> str:\n",
    "    tok_tensor = tok.encode(prompt, return_tensors='pt').to(device) # return_tensors = \"pt\" returns a PyTorch tensor\n",
    "    mdl.eval()\n",
    "    mdl.to(device)\n",
    "    out = mdl.generate(tok_tensor, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, output_scores=True, return_dict_in_generate=True)\n",
    "    text = tok.decode(out.sequences[0], skip_special_tokens=True)\n",
    "    scores = out.scores[0]\n",
    "    return {\"text\": text, \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(inputs):\n",
    "    responses = []\n",
    "    confidences = []\n",
    "    for x in inputs:\n",
    "        res = generate_sentence(tokenizer, model, x, device='cuda')\n",
    "        model_response = res[\"text\"][len(x):]\n",
    "        responses.append(model_response)\n",
    "        confidences.append(res[\"scores\"])\n",
    "    return (responses, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.add(same_animal_test, capability=\"same token prediction\")\n",
    "suite.add(same_country_test, capability=\"same token prediction\")\n",
    "suite.add(same_person_test, capability=\"same token prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suite.run(generate_responses, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to file\n",
    "\n",
    "1. Use serial ids.\n",
    "2. The output file format from the Test Suite should be JSON of the form:\n",
    "```\n",
    "{\n",
    "  examples: [\n",
    "    {\n",
    "        \"id\": <example-id>,\n",
    "        \"content\": <example-content>,\n",
    "        \"metadata\": <example-metadata-as-dict>\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Notes\n",
    "We need to create the output file manually without any of the checklist built-in methods.\n",
    "\n",
    "suite.to_raw_file() will print a line out to the file for each example in the test suite\n",
    "\n",
    "suite.to_dict() will create a dict of lists, where each list has 1 entry per example\n",
    "\n",
    "suite.get_raw_examples() will export all the examples to a list using the format function\n",
    "\n",
    "```\n",
    "suite.to_raw_file(filename, format_fn = lambda x: json.dumps({'example': x, 'id': counter.get_id()}))\n",
    "return suite.to_dict(example_to_dict_fn = lambda x: {'example': x, 'id': counter.get_id()})\n",
    "return suite.get_raw_examples(format_fn = lambda x: {'content': x, 'id': counter.get_id()})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same animal in response\n",
      "Same country in response\n",
      "Same person in response\n"
     ]
    }
   ],
   "source": [
    "for key in suite.tests.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dog is running in the zoo',\n",
       " 'The cat is running in the zoo',\n",
       " 'The giraffe is running in the zoo',\n",
       " 'The aardvark is running in the zoo']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite.tests['Same animal in response'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'animal': 'dog'},\n",
       " {'animal': 'cat'},\n",
       " {'animal': 'giraffe'},\n",
       " {'animal': 'aardvark'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite.tests['Same animal in response'].meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def suite_to_json(suite):\n",
    "    output = {\"examples\": []}\n",
    "    example_id = 1\n",
    "    for test_name in suite.tests.keys():\n",
    "        test = suite.tests[test_name]\n",
    "        for (i, x) in enumerate(test.data):\n",
    "            example_data = {\n",
    "                \"id\": example_id,\n",
    "                \"content\": test.data[i],\n",
    "                \"metadata\": test.meta[i],\n",
    "                \"test_name\": test_name\n",
    "            }\n",
    "            output[\"examples\"].append(example_data)\n",
    "            example_id += 1\n",
    "    return json.dumps(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suite_to_file(suite, filename: str):\n",
    "    with open(filename, \"w\") as text_file:\n",
    "        suite_json = suite_to_json(suite)\n",
    "        text_file.write(suite_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_to_file(suite, 'same_token_suite.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"examples\": [{\"id\": 1, \"content\": \"The dog is running in the zoo\", \"metadata\": {\"animal\": \"dog\"}, \"test_name\": \"Same animal in response\"}, {\"id\": 2, \"content\": \"The cat is running in the zoo\", \"metadata\": {\"animal\": \"cat\"}, \"test_name\": \"Same animal in response\"}, {\"id\": 3, \"content\": \"The giraffe is running in the zoo\", \"metadata\": {\"animal\": \"giraffe\"}, \"test_name\": \"Same animal in response\"}, {\"id\": 4, \"content\": \"The aardvark is running in the zoo\", \"metadata\": {\"animal\": \"aardvark\"}, \"test_name\": \"Same animal in response\"}, {\"id\": 5, \"content\": \"I want to travel to Angola next year.\", \"metadata\": {\"country\": \"Angola\"}, \"test_name\": \"Same country in response\"}, {\"id\": 6, \"content\": \"I want to travel to Federated States of Micronesia next year.\", \"metadata\": {\"country\": \"Federated States of Micronesia\"}, \"test_name\": \"Same country in response\"}, {\"id\": 7, \"content\": \"I want to travel to Pakistan next year.\", \"metadata\": {\"country\": \"Pakistan\"}, \"test_name\": \"Same country in response\"}, {\"id\": 8, \"content\": \"I want to travel to Benin next year.\", \"metadata\": {\"country\": \"Benin\"}, \"test_name\": \"Same country in response\"}, {\"id\": 9, \"content\": \"I want to travel to Dominica next year.\", \"metadata\": {\"country\": \"Dominica\"}, \"test_name\": \"Same country in response\"}, {\"id\": 10, \"content\": \"I want to travel to Kyrgyzstan next year.\", \"metadata\": {\"country\": \"Kyrgyzstan\"}, \"test_name\": \"Same country in response\"}, {\"id\": 11, \"content\": \"I want to travel to Egypt next year.\", \"metadata\": {\"country\": \"Egypt\"}, \"test_name\": \"Same country in response\"}, {\"id\": 12, \"content\": \"I want to travel to South Korea next year.\", \"metadata\": {\"country\": \"South Korea\"}, \"test_name\": \"Same country in response\"}, {\"id\": 13, \"content\": \"I want to travel to Turkey next year.\", \"metadata\": {\"country\": \"Turkey\"}, \"test_name\": \"Same country in response\"}, {\"id\": 14, \"content\": \"I want to travel to Moldova next year.\", \"metadata\": {\"country\": \"Moldova\"}, \"test_name\": \"Same country in response\"}, {\"id\": 15, \"content\": \"Charlie is my best friend.\", \"metadata\": {\"first_name\": \"Charlie\"}, \"test_name\": \"Same person in response\"}, {\"id\": 16, \"content\": \"Dan is my best friend.\", \"metadata\": {\"first_name\": \"Dan\"}, \"test_name\": \"Same person in response\"}, {\"id\": 17, \"content\": \"Ron is my best friend.\", \"metadata\": {\"first_name\": \"Ron\"}, \"test_name\": \"Same person in response\"}, {\"id\": 18, \"content\": \"Jay is my best friend.\", \"metadata\": {\"first_name\": \"Jay\"}, \"test_name\": \"Same person in response\"}, {\"id\": 19, \"content\": \"Thomas is my best friend.\", \"metadata\": {\"first_name\": \"Thomas\"}, \"test_name\": \"Same person in response\"}, {\"id\": 20, \"content\": \"Katie is my best friend.\", \"metadata\": {\"first_name\": \"Katie\"}, \"test_name\": \"Same person in response\"}, {\"id\": 21, \"content\": \"Benjamin is my best friend.\", \"metadata\": {\"first_name\": \"Benjamin\"}, \"test_name\": \"Same person in response\"}, {\"id\": 22, \"content\": \"Johnny is my best friend.\", \"metadata\": {\"first_name\": \"Johnny\"}, \"test_name\": \"Same person in response\"}, {\"id\": 23, \"content\": \"Virginia is my best friend.\", \"metadata\": {\"first_name\": \"Virginia\"}, \"test_name\": \"Same person in response\"}, {\"id\": 24, \"content\": \"Helen is my best friend.\", \"metadata\": {\"first_name\": \"Helen\"}, \"test_name\": \"Same person in response\"}]}"
     ]
    }
   ],
   "source": [
    "cat 'same_token_suite.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'content': 'The dog is running in the zoo',\n",
       "  'metadata': {'animal': 'dog'},\n",
       "  'test_name': 'Same animal in response'},\n",
       " {'id': 2,\n",
       "  'content': 'The cat is running in the zoo',\n",
       "  'metadata': {'animal': 'cat'},\n",
       "  'test_name': 'Same animal in response'},\n",
       " {'id': 3,\n",
       "  'content': 'The giraffe is running in the zoo',\n",
       "  'metadata': {'animal': 'giraffe'},\n",
       "  'test_name': 'Same animal in response'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "f = open('same_token_suite.json', 'r')\n",
    "suite_dict = json.load(f)\n",
    "f.close()\n",
    "suite_dict['examples'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(prompt):\n",
    "    res = generate_sentence(tokenizer, model, prompt, device='cuda')\n",
    "    prediction = res[\"text\"][len(prompt):]\n",
    "    score = res[\"scores\"]\n",
    "    return (prediction, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('same_token_suite_predictions.txt', 'w') as f:\n",
    "    for example in suite_dict['examples']:\n",
    "        prediction = generate_prediction(example['content'])[0]\n",
    "        # Checklist requires 1 line per example\n",
    "        prediction = prediction.replace('\\n', ' ') + '\\n'\n",
    "        f.write(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".  \"It's been a long time since I've seen a dog run in a zoo,\" he said. \"I've never seen anything like this before.\"\r\n",
      ".  \"I don't know what's going on,\" he said. \"I've never seen anything like this before.\"\r\n",
      ".  \"It's been a long time coming, but it's finally here,\" he said.\r\n",
      ".  \"It's been a long time coming,\" he said. \"I've never seen anything like it before.\"\r\n",
      "  \"I'm not sure if I'll be able to do it,\" he said. \"I don't know if it's going to be a long trip or not, but I'm sure it will be worth it.\"\r\n",
      " I'm going to be able to do that,\" he said.\r\n",
      "  \"I'm not going to stay in Pakistan. I don't know what to do with my life,\" he said.\r\n",
      "  \"I'm not going to be able to do that. I'm just not sure what I can do.\"\r\n",
      "  \"It's a great opportunity for me,\" he said. \"I'm looking forward to it.\"\r\n",
      "  \"I'm not sure if I'll be able to do it, but I'm looking forward to it,\" he said.\r\n",
      " I don't know if I'll be able to do it,\" he said.  \"I'm not sure what I can do, but I'm looking forward to it.\"\r\n",
      " It's a great opportunity for me to get to know the people there and see what they have to offer.\"\r\n",
      " I don't know if I'll be able to do it,\" he said.  \"I'm not sure what I can do, but I'm looking forward to it.\"\r\n",
      "  \"I'm very happy to be here,\" he said.\r\n",
      " He's always been there for me.\"  \"I love you,\" she said. \"I'm so glad you're here. It's been a long time since I've been here, but I can't wait to see you again.\"\r\n",
      " He's been with me since I was a kid, and he's always been there for me.  \"I've always wanted to be with him, but I don't know if I'll ever be able to do it. I'm not sure if it's going to happen or not. It's just a matter of time.\"\r\n",
      " He's always been there for me and always will be.  \"He's a great guy and I'm very proud of him. I think he's going to be one of the best players in the league for a long time.\"\r\n",
      " He's always been there for me and always will be. I love him and I'm so happy to be here with him.  \"He's a great guy and he's going to do everything he can to help me get to where I want to go.\"\r\n",
      " I love him. He's a great guy.  \"I don't know what he's going to do, but I think he'll be fine.\"\r\n",
      " I love her so much. She's so sweet, and I'm so happy to have her back.  I'm not sure if I'll ever be able to say goodbye to her, but I can't wait to see what she's going to do next.\r\n",
      " He's a good guy, and he's always been there for me.\"  \"I'm not going to lie to you,\" he said. \"I love you.\"\r\n",
      " I love him so much. He's such a good guy.  \"He's a great guy, but he's not the best person to be around. It's hard for me to talk to him, because I don't know what to say.\"\r\n",
      " I love him. He's a great guy.  \"I'm not going to lie to you, but I think he's the best player in the league right now. It's just a matter of time before we get to know each other.\"\r\n",
      " I love her so much, and she's always been my favorite.  I'm so glad you're here. Thank you for taking the time to read this. It's been so long since I've been here, but I can't wait to see what you have in store for us.\r\n"
     ]
    }
   ],
   "source": [
    "cat 'same_token_suite_predictions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.run_from_file('same_token_suite_predictions.txt', file_format='pred_only', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same token prediction\n",
      "\n",
      "Same animal in response\n",
      "Test cases:      4\n",
      "Fails (rate):    3 (75.0%)\n",
      "\n",
      "Example fails:\n",
      ".  \"It's been a long time coming,\" he said. \"I've never seen anything like it before.\" The aardvark is running in the zoo\n",
      "----\n",
      ".  \"I don't know what's going on,\" he said. \"I've never seen anything like this before.\" The cat is running in the zoo\n",
      "----\n",
      ".  \"It's been a long time coming, but it's finally here,\" he said. The giraffe is running in the zoo\n",
      "----\n",
      "\n",
      "\n",
      "Same country in response\n",
      "Test cases:      10\n",
      "Fails (rate):    9 (90.0%)\n",
      "\n",
      "Example fails:\n",
      "  \"I'm not sure if I'll be able to do it, but I'm looking forward to it,\" he said. I want to travel to Kyrgyzstan next year.\n",
      "----\n",
      "  \"I'm not going to be able to do that. I'm just not sure what I can do.\" I want to travel to Benin next year.\n",
      "----\n",
      "  \"It's a great opportunity for me,\" he said. \"I'm looking forward to it.\" I want to travel to Dominica next year.\n",
      "----\n",
      "\n",
      "\n",
      "Same person in response\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      " He's always been there for me and always will be. I love him and I'm so happy to be here with him.  \"He's a great guy and he's going to do everything he can to help me get to where I want to go.\" Jay is my best friend.\n",
      "----\n",
      " He's a good guy, and he's always been there for me.\"  \"I'm not going to lie to you,\" he said. \"I love you.\" Benjamin is my best friend.\n",
      "----\n",
      " I love her so much, and she's always been my favorite.  I'm so glad you're here. Thank you for taking the time to read this. It's been so long since I've been here, but I can't wait to see what you have in store for us. Helen is my best friend.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23deb80321664abaad4a422cf7e70c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Same animal in respo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============= Scratch Area ============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next token invariant MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token(tokenizer, model, prompt, top_k=5, device='cuda'):\n",
    "    prompt = prompt.strip()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    input_tokenized_length = input_ids.size(1)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids, \n",
    "        max_length=(input_tokenized_length + 1), \n",
    "        num_beams=top_k, \n",
    "        num_return_sequences=top_k, \n",
    "        early_stopping=True,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True\n",
    "    )\n",
    "\n",
    "    sequence_probabilities = F.softmax(beam_outputs.sequences_scores, dim=0)\n",
    "    \n",
    "    token_scores = []\n",
    "    for i, beam_output in enumerate(beam_outputs.sequences):\n",
    "        sequence_score = sequence_probabilities[i].item()\n",
    "        decoded_sequence = tokenizer.decode(beam_output, skip_special_tokens=True)\n",
    "        new_token = decoded_sequence[len(prompt):]\n",
    "        token_scores.append((new_token, sequence_score))\n",
    "    \n",
    "    return token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' lawyer', 0.21111242473125458),\n",
       " (' writer', 0.2087818831205368),\n",
       " (' consultant', 0.20089176297187805),\n",
       " (' journalist', 0.19572344422340393),\n",
       " (' freelance', 0.18349044024944305)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_token(tokenizer, model, \"John works as a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'data': ['The state of Delaware is located in the United ', 'The state of Tennessee is located in the United ', 'The state of Georgia is located in the United ', 'The state of Washington is located in the United ', 'The state of Oregon is located in the United ', 'The state of California is located in the United ', 'The state of New Mexico is located in the United ', 'The state of Alaska is located in the United ', 'The state of Hawaii is located in the United ', 'The state of Colorado is located in the United ']})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = editor.template('The state of {state} is located in the United ', state=['Delaware', 'Tennessee', 'Georgia', 'Washington', 'Oregon', 'California', 'New Mexico', 'Alaska', 'Hawaii', 'Colorado'])\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state of Delaware is located in the United \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' States', 0.29671230912208557),\n",
       " (' Kingdom', 0.23459471762180328),\n",
       " (' State', 0.16363166272640228),\n",
       " (' states', 0.152780219912529),\n",
       " (' Nations', 0.15228109061717987)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prompts.data[0])\n",
    "predict_next_token(tokenizer, model, prompts.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(inputs):\n",
    "    responses = []\n",
    "    confidences = []\n",
    "    for prompt in inputs:\n",
    "        predictions = predict_next_token(tokenizer, model, prompt, device='cuda')\n",
    "        next_tokens = []\n",
    "        token_confidences = []\n",
    "        for pred in predictions:\n",
    "            next_tokens.append(pred[0])\n",
    "            token_confidences.append(pred[1])\n",
    "        responses.append(next_tokens)\n",
    "        confidences.append(token_confidences)\n",
    "    return (responses, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expect_fn():\n",
    "    def e_fn(x, pred, conf, label=None, meta=None, run_idxs=None):\n",
    "        seen_tokens = set()\n",
    "        results = []\n",
    "        for p in pred:\n",
    "            for token in p:\n",
    "                seen_tokens.add(token)\n",
    "        for p in pred:\n",
    "            example_tokens = set()\n",
    "            for token in p:\n",
    "                example_tokens.add(token)\n",
    "            results.append([example_tokens == seen_tokens])\n",
    "        return results\n",
    "    return Expect.test(e_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect = make_expect_fn()\n",
    "next_token_test = MFT(**prompts, name='Next token invariant', description='The next predicted token is invariant for each prompt', expect=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n"
     ]
    }
   ],
   "source": [
    "next_token_test.run(generate_test_predictions, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[' States', ' Kingdom', ' State', ' states', ' Nations'] The state of Delaware is located in the United \n",
      "\n",
      "----\n",
      "[' States', ' Kingdom', ' Nations', ' State', ' Arab'] The state of Hawaii is located in the United \n",
      "\n",
      "----\n",
      "[' States', ' Kingdom', ' State', ' states', ' Nations'] The state of New Mexico is located in the United \n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "next_token_test.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
