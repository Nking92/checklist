{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.expect import Expect\n",
    "from checklist.test_types import MFT\n",
    "from torch.nn import functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# Load pretrained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dog is running in the zoo',\n",
       " 'The cat is running in the zoo',\n",
       " 'The giraffe is running in the zoo',\n",
       " 'The aardvark is running in the zoo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = Editor()\n",
    "animal_prompts = editor.template(\"The {animal} is running in the zoo\", animal=[\"dog\", \"cat\", \"giraffe\", \"aardvark\"], meta=True)\n",
    "animal_prompts.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_animal(x, pred, conf, label=None, meta=None):\n",
    "    return meta['animal'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_animal_expect_fn = Expect.single(contains_same_animal)\n",
    "same_animal_test = MFT(**animal_prompts, name='Same animal in response', description='The response contains the same animal mentioned in the prompt.', expect=same_animal_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'meta': [{'country': 'Saint Vincent and the Grenadines'}, {'country': 'Andorra'}, {'country': 'Yemen'}, {'country': 'Finland'}, {'country': 'Seychelles'}, {'country': 'Italy'}, {'country': 'Malta'}, {'country': 'Maldives'}, {'country': 'Uganda'}, {'country': 'Jordan'}], 'data': ['I want to travel to Saint Vincent and the Grenadines next year.', 'I want to travel to Andorra next year.', 'I want to travel to Yemen next year.', 'I want to travel to Finland next year.', 'I want to travel to Seychelles next year.', 'I want to travel to Italy next year.', 'I want to travel to Malta next year.', 'I want to travel to Maldives next year.', 'I want to travel to Uganda next year.', 'I want to travel to Jordan next year.']})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_prompts = editor.template(\"I want to travel to {country} next year.\", meta=True, nsamples=10)\n",
    "country_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_country(x, pred, conf, label=None, meta=None):\n",
    "    return meta['country'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_country_expect_fn = Expect.single(contains_same_country)\n",
    "same_country_test = MFT(**country_prompts, name='Same country in response', description='The response contains the same country mentioned in the prompt.', expect=same_country_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'meta': [{'first_name': 'Henry'}, {'first_name': 'Fred'}, {'first_name': 'Bob'}, {'first_name': 'Daniel'}, {'first_name': 'Michelle'}, {'first_name': 'Bob'}, {'first_name': 'Tim'}, {'first_name': 'Albert'}, {'first_name': 'Victoria'}, {'first_name': 'Jay'}], 'data': ['Henry is my best friend.', 'Fred is my best friend.', 'Bob is my best friend.', 'Daniel is my best friend.', 'Michelle is my best friend.', 'Bob is my best friend.', 'Tim is my best friend.', 'Albert is my best friend.', 'Victoria is my best friend.', 'Jay is my best friend.']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_prompts = editor.template(\"{first_name} is my best friend.\", meta=True, nsamples=10)\n",
    "person_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_person(x, pred, conf, label=None, meta=None):\n",
    "    return meta['first_name'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_person_expect_fn = Expect.single(contains_same_person)\n",
    "same_person_test = MFT(**person_prompts, name='Same person in response', description='The response contains the same person mentioned in the prompt.', expect=same_person_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(tok, mdl, prompt, max_length=150, device='cuda') -> str:\n",
    "    tok_tensor = tok.encode(prompt, return_tensors='pt').to(device) # return_tensors = \"pt\" returns a PyTorch tensor\n",
    "    mdl.eval()\n",
    "    mdl.to(device)\n",
    "    out = mdl.generate(tok_tensor, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, output_scores=True, return_dict_in_generate=True)\n",
    "    text = tok.decode(out.sequences[0], skip_special_tokens=True)\n",
    "    scores = out.scores[0]\n",
    "    return {\"text\": text, \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(inputs):\n",
    "    responses = []\n",
    "    confidences = []\n",
    "    for x in inputs:\n",
    "        res = generate_sentence(tokenizer, model, x, device='cuda')\n",
    "        model_response = res[\"text\"][len(x):]\n",
    "        responses.append(model_response)\n",
    "        confidences.append(res[\"scores\"])\n",
    "    return (responses, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.add(same_animal_test, capability=\"same token prediction\")\n",
    "suite.add(same_country_test, capability=\"same token prediction\")\n",
    "suite.add(same_person_test, capability=\"same token prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suite.run(generate_responses, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to file\n",
    "\n",
    "1. Use serial ids.\n",
    "2. The output file format from the Test Suite should be JSON of the form:\n",
    "```\n",
    "{\n",
    "  examples: [\n",
    "    {\n",
    "        \"id\": <example-id>,\n",
    "        \"content\": <example-content>,\n",
    "        \"metadata\": <example-metadata-as-dict>\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Notes\n",
    "We need to create the output file manually without any of the checklist built-in methods.\n",
    "\n",
    "suite.to_raw_file() will print a line out to the file for each example in the test suite\n",
    "\n",
    "suite.to_dict() will create a dict of lists, where each list has 1 entry per example\n",
    "\n",
    "suite.get_raw_examples() will export all the examples to a list using the format function\n",
    "\n",
    "```\n",
    "suite.to_raw_file(filename, format_fn = lambda x: json.dumps({'example': x, 'id': counter.get_id()}))\n",
    "return suite.to_dict(example_to_dict_fn = lambda x: {'example': x, 'id': counter.get_id()})\n",
    "return suite.get_raw_examples(format_fn = lambda x: {'content': x, 'id': counter.get_id()})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same animal in response\n",
      "Same country in response\n",
      "Same person in response\n"
     ]
    }
   ],
   "source": [
    "for key in suite.tests.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dog is running in the zoo',\n",
       " 'The cat is running in the zoo',\n",
       " 'The giraffe is running in the zoo',\n",
       " 'The aardvark is running in the zoo']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite.tests['Same animal in response'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'animal': 'dog'},\n",
       " {'animal': 'cat'},\n",
       " {'animal': 'giraffe'},\n",
       " {'animal': 'aardvark'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suite.tests['Same animal in response'].meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suite_to_json_file(suite, filename):\n",
    "    class Counter:\n",
    "        def __init__(self):\n",
    "            self.count = 0\n",
    "        def get_count(self):\n",
    "            self.count += 1\n",
    "            return self.count\n",
    "    \n",
    "    counter = Counter()\n",
    "    total_tests = 0\n",
    "    for t in suite.tests.values():\n",
    "        total_tests += len(t.data)\n",
    "        \n",
    "    def json_format_fn(x):\n",
    "        example_id = counter.get_count()\n",
    "        json_str = \"\"\n",
    "        if example_id == 1:\n",
    "            json_str = '{\"examples\": ['\n",
    "        json_str += json.dumps({'content': x, 'id': example_id}) + \",\"\n",
    "        if example_id == total_tests:\n",
    "            # remove trailing comma\n",
    "            json_str = json_str[:len(json_str)-1]\n",
    "            json_str += \"]}\"\n",
    "        return json_str\n",
    "    \n",
    "    suite.to_raw_file(filename, format_fn = json_format_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use to_raw_file for part of the output (because we have to call it before run_from_file)\n",
    "suite_to_json_file(suite, 'same_token_suite.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"examples\": [{\"content\": \"The dog is running in the zoo\", \"id\": 1},\r\n",
      "{\"content\": \"The cat is running in the zoo\", \"id\": 2},\r\n",
      "{\"content\": \"The giraffe is running in the zoo\", \"id\": 3},\r\n",
      "{\"content\": \"The aardvark is running in the zoo\", \"id\": 4},\r\n",
      "{\"content\": \"I want to travel to Saint Vincent and the Grenadines next year.\", \"id\": 5},\r\n",
      "{\"content\": \"I want to travel to Andorra next year.\", \"id\": 6},\r\n",
      "{\"content\": \"I want to travel to Yemen next year.\", \"id\": 7},\r\n",
      "{\"content\": \"I want to travel to Finland next year.\", \"id\": 8},\r\n",
      "{\"content\": \"I want to travel to Seychelles next year.\", \"id\": 9},\r\n",
      "{\"content\": \"I want to travel to Italy next year.\", \"id\": 10},\r\n",
      "{\"content\": \"I want to travel to Malta next year.\", \"id\": 11},\r\n",
      "{\"content\": \"I want to travel to Maldives next year.\", \"id\": 12},\r\n",
      "{\"content\": \"I want to travel to Uganda next year.\", \"id\": 13},\r\n",
      "{\"content\": \"I want to travel to Jordan next year.\", \"id\": 14},\r\n",
      "{\"content\": \"Henry is my best friend.\", \"id\": 15},\r\n",
      "{\"content\": \"Fred is my best friend.\", \"id\": 16},\r\n",
      "{\"content\": \"Bob is my best friend.\", \"id\": 17},\r\n",
      "{\"content\": \"Daniel is my best friend.\", \"id\": 18},\r\n",
      "{\"content\": \"Michelle is my best friend.\", \"id\": 19},\r\n",
      "{\"content\": \"Bob is my best friend.\", \"id\": 20},\r\n",
      "{\"content\": \"Tim is my best friend.\", \"id\": 21},\r\n",
      "{\"content\": \"Albert is my best friend.\", \"id\": 22},\r\n",
      "{\"content\": \"Victoria is my best friend.\", \"id\": 23},\r\n",
      "{\"content\": \"Jay is my best friend.\", \"id\": 24}]}"
     ]
    }
   ],
   "source": [
    "cat 'same_token_suite.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'The dog is running in the zoo', 'id': 1},\n",
       " {'content': 'The cat is running in the zoo', 'id': 2},\n",
       " {'content': 'The giraffe is running in the zoo', 'id': 3}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "f = open('same_token_suite.json', 'r')\n",
    "suite_dict = json.load(f)\n",
    "f.close()\n",
    "suite_dict['examples'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(prompt):\n",
    "    res = generate_sentence(tokenizer, model, prompt, device='cuda')\n",
    "    prediction = res[\"text\"][len(prompt):]\n",
    "    score = res[\"scores\"]\n",
    "    return (prediction, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('same_token_suite_predictions.txt', 'w') as f:\n",
    "    example_id = 1\n",
    "    for example in suite_dict['examples']:\n",
    "        prediction = generate_prediction(example['content'])[0]\n",
    "        prediction = prediction.replace('\"', '\\\"')\n",
    "        f.write(json.dumps({'prediction': prediction, 'id': example_id}) + '\\n')\n",
    "        example_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"prediction\": \".\\n\\n\\\"It's been a long time since I've seen a dog run in a zoo,\\\" he said. \\\"I've never seen anything like this before.\\\"\", \"id\": 1}\r\n",
      "{\"prediction\": \".\\n\\n\\\"I don't know what's going on,\\\" he said. \\\"I've never seen anything like this before.\\\"\", \"id\": 2}\r\n",
      "{\"prediction\": \".\\n\\n\\\"It's been a long time coming, but it's finally here,\\\" he said.\", \"id\": 3}\r\n",
      "{\"prediction\": \".\\n\\n\\\"It's been a long time coming,\\\" he said. \\\"I've never seen anything like it before.\\\"\", \"id\": 4}\r\n",
      "{\"prediction\": \"\\n\\n\\\"It's a great opportunity for me and my family to get to know each other and see what's going on in the world.\\\"\", \"id\": 5}\r\n",
      "{\"prediction\": \"\\n\\n\\\"I'm not going to be able to do that,\\\" he said.\", \"id\": 6}\r\n",
      "{\"prediction\": \" I'm going to go to Saudi Arabia and I'll be able to do that,\\\" he said.\\n\\n\\\"I don't know if it's a good idea or not, but I think it would be a great idea.\\\"\", \"id\": 7}\r\n",
      "{\"prediction\": \"\\n\\n\\\"I don't know if I'll be able to do it, but I'm looking forward to it.\\\"\", \"id\": 8}\r\n",
      "{\"prediction\": \"\\n\\n\\\"I don't know if I'll be able to do it, but I'm looking forward to it.\\\"\", \"id\": 9}\r\n",
      "{\"prediction\": \"\\n\\n\\\"I don't know if I'll be able to do it, but I'm looking forward to it.\\\"\", \"id\": 10}\r\n",
      "{\"prediction\": \"\\n\\n\\\"It's a great opportunity for me and my family. It's also a chance for us to get to know each other. I'm really looking forward to it.\\\"\", \"id\": 11}\r\n",
      "{\"prediction\": \"\\n\\n\\\"It's a great opportunity for me to get to know the people there. It's also a chance for us to learn from each other.\\\"\", \"id\": 12}\r\n",
      "{\"prediction\": \"\\n\\n\\\"I'm not going to be able to do it because I'm too young and I don't have the money to go to school. But I will go. I'll go.\\\"\", \"id\": 13}\r\n",
      "{\"prediction\": \" It's a great opportunity for me to get to know the people there and see what they have to offer.\\n\\n\\\"I'm looking forward to it.\\\"\", \"id\": 14}\r\n",
      "{\"prediction\": \" I love him. He's a great guy.\\n\\n\\\"I'm not going to lie to you, but I think he's the best player I've ever played with in my life. It's just a matter of time before we get to know each other.\\\"\", \"id\": 15}\r\n",
      "{\"prediction\": \" He's always been there for me and always will be. I love him.\\n\\n\\\"He's a great guy and I'm very proud of him.\\\"\", \"id\": 16}\r\n",
      "{\"prediction\": \" He's always been there for me and always will be.\\n\\n\\\"He's a great guy and I'm very proud of him. I think he's one of the nicest people I've ever met.\\\"\", \"id\": 17}\r\n",
      "{\"prediction\": \" He's a great guy, and he's always been there for me.\\n\\n\\\"I've always wanted to be with him, but I've never been able to do it. It's been a long time since we've been together, so I'm really looking forward to it.\\\"\", \"id\": 18}\r\n",
      "{\"prediction\": \" I love her so much. She's a great person and I'm so happy to have her back.\\n\\nWhat do you think of the new season of \\\"The Real Housewives of Beverly Hills\\\"? Let us know in the comments below.\", \"id\": 19}\r\n",
      "{\"prediction\": \" He's always been there for me and always will be.\\n\\n\\\"He's a great guy and I'm very proud of him. I think he's one of the nicest people I've ever met.\\\"\", \"id\": 20}\r\n",
      "{\"prediction\": \" He's a great guy, and he's always been there for me.\\n\\n\\\"He's the best person I've ever known. I'm so proud of him.\\\"\", \"id\": 21}\r\n",
      "{\"prediction\": \" He's a great guy, and I'm very proud of him.\\n\\n\\\"I think he's going to be a very good player for us. We've got a lot of work to do.\\\"\", \"id\": 22}\r\n",
      "{\"prediction\": \" I love her so much, and she's always been there for me.\\n\\n\\\"I've always wanted to be with her, but I don't know if I'll ever be able to do it. It's been a long time since I've been with someone like that, so I'm really looking forward to it.\\\"\", \"id\": 23}\r\n",
      "{\"prediction\": \" He's always been there for me and always will be. I love him and I'm so happy to be here with him.\\n\\n\\\"He's a great guy and he's going to do everything he can to help me get to where I want to go.\\\"\", \"id\": 24}\r\n"
     ]
    }
   ],
   "source": [
    "cat 'same_token_suite_predictions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_prediction(x):\n",
    "    test_output = json.load(x)\n",
    "    return test_output['prediction']\n",
    "suite.run_from_file('same_token_suite_predictions.txt', file_format='pred_only', format_fn = read_json_prediction, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same token prediction\n",
      "\n",
      "Same animal in response\n",
      "Test cases:      4\n",
      "Fails (rate):    3 (75.0%)\n",
      "\n",
      "Example fails:\n",
      "{\"prediction\": \".\\n\\n\\\"It's been a long time coming, but it's finally here,\\\" he said.\", \"id\": 3} The giraffe is running in the zoo\n",
      "----\n",
      "{\"prediction\": \".\\n\\n\\\"It's been a long time coming,\\\" he said. \\\"I've never seen anything like it before.\\\"\", \"id\": 4} The aardvark is running in the zoo\n",
      "----\n",
      "{\"prediction\": \".\\n\\n\\\"I don't know what's going on,\\\" he said. \\\"I've never seen anything like this before.\\\"\", \"id\": 2} The cat is running in the zoo\n",
      "----\n",
      "\n",
      "\n",
      "Same country in response\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "{\"prediction\": \"\\n\\n\\\"I don't know if I'll be able to do it, but I'm looking forward to it.\\\"\", \"id\": 8} I want to travel to Finland next year.\n",
      "----\n",
      "{\"prediction\": \"\\n\\n\\\"I'm not going to be able to do that,\\\" he said.\", \"id\": 6} I want to travel to Andorra next year.\n",
      "----\n",
      "{\"prediction\": \"\\n\\n\\\"I don't know if I'll be able to do it, but I'm looking forward to it.\\\"\", \"id\": 10} I want to travel to Italy next year.\n",
      "----\n",
      "\n",
      "\n",
      "Same person in response\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "{\"prediction\": \" He's a great guy, and I'm very proud of him.\\n\\n\\\"I think he's going to be a very good player for us. We've got a lot of work to do.\\\"\", \"id\": 22} Albert is my best friend.\n",
      "----\n",
      "{\"prediction\": \" I love her so much, and she's always been there for me.\\n\\n\\\"I've always wanted to be with her, but I don't know if I'll ever be able to do it. It's been a long time since I've been with someone like that, so I'm really looking forward to it.\\\"\", \"id\": 23} Victoria is my best friend.\n",
      "----\n",
      "{\"prediction\": \" I love him. He's a great guy.\\n\\n\\\"I'm not going to lie to you, but I think he's the best player I've ever played with in my life. It's just a matter of time before we get to know each other.\\\"\", \"id\": 15} Henry is my best friend.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8a3a35b6474d78bdc0689ad96c1450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Same animal in respoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
