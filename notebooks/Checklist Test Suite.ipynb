{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import pandas as pd\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.expect import Expect\n",
    "from checklist.test_types import MFT\n",
    "from torch.nn import functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# Load pretrained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dog is running in the zoo',\n",
       " 'The cat is running in the zoo',\n",
       " 'The giraffe is running in the zoo',\n",
       " 'The aardvark is running in the zoo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = Editor()\n",
    "animal_prompts = editor.template(\"The {animal} is running in the zoo\", animal=[\"dog\", \"cat\", \"giraffe\", \"aardvark\"], meta=True)\n",
    "animal_prompts.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_animal(x, pred, conf, label=None, meta=None):\n",
    "    return meta['animal'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_animal_expect_fn = Expect.single(contains_same_animal)\n",
    "same_animal_test = MFT(**animal_prompts, name='Same animal in response', description='The response contains the same animal mentioned in the prompt.', expect=same_animal_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'meta': [{'country': 'Japan'}, {'country': 'Germany'}, {'country': 'Somalia'}, {'country': 'Ukraine'}, {'country': 'Cape Verde'}, {'country': 'Tajikistan'}, {'country': 'Cambodia'}, {'country': 'Latvia'}, {'country': 'Ghana'}, {'country': 'Antigua and Barbuda'}], 'data': ['I want to travel to Japan next year.', 'I want to travel to Germany next year.', 'I want to travel to Somalia next year.', 'I want to travel to Ukraine next year.', 'I want to travel to Cape Verde next year.', 'I want to travel to Tajikistan next year.', 'I want to travel to Cambodia next year.', 'I want to travel to Latvia next year.', 'I want to travel to Ghana next year.', 'I want to travel to Antigua and Barbuda next year.']})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_prompts = editor.template(\"I want to travel to {country} next year.\", meta=True, nsamples=10)\n",
    "country_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_country(x, pred, conf, label=None, meta=None):\n",
    "    return meta['country'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_country_expect_fn = Expect.single(contains_same_country)\n",
    "same_country_test = MFT(**country_prompts, name='Same country in response', description='The response contains the same country mentioned in the prompt.', expect=same_country_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'meta': [{'first_name': 'Martha'}, {'first_name': 'Florence'}, {'first_name': 'Don'}, {'first_name': 'Steven'}, {'first_name': 'Amy'}, {'first_name': 'Ruth'}, {'first_name': 'Louise'}, {'first_name': 'Katherine'}, {'first_name': 'Elizabeth'}, {'first_name': 'Bob'}], 'data': ['Martha is my best friend.', 'Florence is my best friend.', 'Don is my best friend.', 'Steven is my best friend.', 'Amy is my best friend.', 'Ruth is my best friend.', 'Louise is my best friend.', 'Katherine is my best friend.', 'Elizabeth is my best friend.', 'Bob is my best friend.']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_prompts = editor.template(\"{first_name} is my best friend.\", meta=True, nsamples=10)\n",
    "person_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_person(x, pred, conf, label=None, meta=None):\n",
    "    return meta['first_name'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_person_expect_fn = Expect.single(contains_same_person)\n",
    "same_person_test = MFT(**person_prompts, name='Same person in response', description='The response contains the same person mentioned in the prompt.', expect=same_person_expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(tok, mdl, prompt, max_length=150, device='cuda') -> str:\n",
    "    tok_tensor = tok.encode(prompt, return_tensors='pt').to(device) # return_tensors = \"pt\" returns a PyTorch tensor\n",
    "    mdl.eval()\n",
    "    mdl.to(device)\n",
    "    out = mdl.generate(tok_tensor, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, output_scores=True, return_dict_in_generate=True)\n",
    "    text = tok.decode(out.sequences[0], skip_special_tokens=True)\n",
    "    scores = out.scores[0]\n",
    "    return {\"text\": text, \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(inputs):\n",
    "    responses = []\n",
    "    confidences = []\n",
    "    for x in inputs:\n",
    "        res = generate_sentence(tokenizer, model, x, device='cuda')\n",
    "        model_response = res[\"text\"][len(x):]\n",
    "        responses.append(model_response)\n",
    "        confidences.append(res[\"scores\"])\n",
    "    return (responses, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.test_suite import TestSuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite.add(same_animal_test, capability=\"same token prediction\")\n",
    "suite.add(same_country_test, capability=\"same token prediction\")\n",
    "suite.add(same_person_test, capability=\"same token prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Same animal in response\n",
      "Predicting 4 examples\n",
      "Running Same country in response\n",
      "Predicting 10 examples\n",
      "Running Same person in response\n",
      "Predicting 10 examples\n"
     ]
    }
   ],
   "source": [
    "suite.run(generate_responses, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same token prediction\n",
      "\n",
      "Same animal in response\n",
      "Test cases:      4\n",
      "Fails (rate):    3 (75.0%)\n",
      "\n",
      "Example fails:\n",
      ".\n",
      "\n",
      "\"I don't know what's going on,\" he said. \"I've never seen anything like this before.\" The cat is running in the zoo\n",
      "----\n",
      ".\n",
      "\n",
      "\"It's been a long time coming, but it's finally here,\" he said. The giraffe is running in the zoo\n",
      "----\n",
      ".\n",
      "\n",
      "\"It's been a long time coming,\" he said. \"I've never seen anything like it before.\" The aardvark is running in the zoo\n",
      "----\n",
      "\n",
      "\n",
      "Same country in response\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "\n",
      "\n",
      "\"I don't know if I'll be able to do it, but I'm looking forward to it.\" I want to travel to Latvia next year.\n",
      "----\n",
      "\n",
      "\n",
      "\"I'm not going to be able to go to the United States. I don't know where I'm going,\" he said. I want to travel to Somalia next year.\n",
      "----\n",
      "\n",
      "\n",
      "\"I'm not going to stay here. I don't know what to do,\" he said. \"I have no idea what I can do.\" I want to travel to Tajikistan next year.\n",
      "----\n",
      "\n",
      "\n",
      "Same person in response\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      " I love her so much, and she's always been my favorite person to hang out with.\n",
      "\n",
      "I've always wanted to be a writer, but I don't know if I can do it without her. She's such an amazing person and I'm so grateful to have her on my team. Katherine is my best friend.\n",
      "----\n",
      " I love her so much. She's so sweet, and I'm so happy to have her back.\n",
      "\n",
      "\"I love you too,\" she says. \"You're such a sweet girl. You're so beautiful. And I can't wait to see what you have to offer me.\" She kisses me on the cheek and says, \"Thank you for everything you've done for me. It's been a long time since I've had a good time with you, but I know you're going to love it.\" I smile at her and she smiles back at me with a big smile on her face. Amy is my best friend.\n",
      "----\n",
      " I love her so much. She's so sweet and I'm so happy to have her back.\"\n",
      "\n",
      "\"I love you too,\" she said. \"I can't wait to see you again.\" Martha is my best friend.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait as we prepare the table data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c676ebcf756431890d82abc8a47ad2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SuiteSummarizer(stats={'npassed': 0, 'nfailed': 0, 'nfiltered': 0}, test_infos=[{'name': 'Same animal in respo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suite.visual_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDs and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example': ['The dog is running in the zoo',\n",
       "  'The cat is running in the zoo',\n",
       "  'The giraffe is running in the zoo',\n",
       "  'The aardvark is running in the zoo',\n",
       "  'I want to travel to Japan next year.',\n",
       "  'I want to travel to Germany next year.',\n",
       "  'I want to travel to Somalia next year.',\n",
       "  'I want to travel to Ukraine next year.',\n",
       "  'I want to travel to Cape Verde next year.',\n",
       "  'I want to travel to Tajikistan next year.',\n",
       "  'I want to travel to Cambodia next year.',\n",
       "  'I want to travel to Latvia next year.',\n",
       "  'I want to travel to Ghana next year.',\n",
       "  'I want to travel to Antigua and Barbuda next year.',\n",
       "  'Martha is my best friend.',\n",
       "  'Florence is my best friend.',\n",
       "  'Don is my best friend.',\n",
       "  'Steven is my best friend.',\n",
       "  'Amy is my best friend.',\n",
       "  'Ruth is my best friend.',\n",
       "  'Louise is my best friend.',\n",
       "  'Katherine is my best friend.',\n",
       "  'Elizabeth is my best friend.',\n",
       "  'Bob is my best friend.'],\n",
       " 'id': ['f95362c7-0ca1-4f02-8d52-7ad90cd9b670',\n",
       "  'bb8f1f2e-eebe-4634-87c0-97d295607bdf',\n",
       "  'c0113b27-7129-424a-a1d6-09546eb57f28',\n",
       "  'd167abc9-26c8-42b6-8942-3ca374809322',\n",
       "  '2860977a-aad4-445a-af53-66b706b445de',\n",
       "  'b18a39d5-dc06-4118-90a9-f5e756a61f66',\n",
       "  'cf26a277-b232-4ad7-8b43-d98fde5b05e9',\n",
       "  '4269908d-351d-4bf7-b28b-4912ef0eb775',\n",
       "  'fce7b203-d0b1-42b6-a2b5-bb8b473c4196',\n",
       "  'e45cdc98-2026-4440-9870-73684a15afe4',\n",
       "  '50640702-27e8-4922-92c1-af73202d6512',\n",
       "  '73b31915-2ca3-4e46-99ad-ab151f4bde0d',\n",
       "  '0a70e6a1-99d6-45f9-8d68-d0c69cce1e35',\n",
       "  'fcfeeacb-3a8b-4a96-93f2-9665a0983a28',\n",
       "  '4e259a0f-96fa-4988-84cf-03f0c9567942',\n",
       "  '0f53b880-637b-4b45-a3e6-7bf0dd93c35a',\n",
       "  'b83c835c-402c-4170-891e-3af99e6b8a87',\n",
       "  '61a31de4-9e79-477e-b4bf-0d6d3cecd8d1',\n",
       "  '9f6b8b78-15f4-4f73-9624-e5d90fad5215',\n",
       "  'a1863083-bee4-4323-9b1e-77129b320a1a',\n",
       "  '880b22d7-2cb7-4f87-9e93-c1ee4f6241e4',\n",
       "  '9f9b15db-e357-4c16-b774-25b378eaba12',\n",
       "  '976f7c7c-82f3-4dfc-a155-07251391ff7f',\n",
       "  'f26d58dd-f524-41d2-9476-6286762690ec'],\n",
       " 'test_name': ['Same animal in response',\n",
       "  'Same animal in response',\n",
       "  'Same animal in response',\n",
       "  'Same animal in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same country in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response',\n",
       "  'Same person in response'],\n",
       " 'test_case': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9],\n",
       " 'example_idx': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "dict_version = suite.to_dict(example_to_dict_fn = lambda x: {'example': x, 'id': str(uuid.uuid4())})\n",
    "dict_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "suite.to_raw_file('same_token_suite.txt', format_fn = lambda x: json.dumps({'example': x, 'id': str(uuid.uuid4())}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"example\": \"The dog is running in the zoo\", \"id\": \"6d3ac2c9-153f-46c5-b7db-c46e43d5a378\"}\r\n",
      "{\"example\": \"The cat is running in the zoo\", \"id\": \"7d4d495c-f120-411a-bf6a-28cc8014e5cf\"}\r\n",
      "{\"example\": \"The giraffe is running in the zoo\", \"id\": \"be6ec2fe-ce37-4112-b95c-405ce2aafeaf\"}\r\n",
      "{\"example\": \"The aardvark is running in the zoo\", \"id\": \"fa27877c-abc5-4209-9d15-eb9163de3285\"}\r\n",
      "{\"example\": \"I want to travel to Japan next year.\", \"id\": \"0e760034-32dc-425c-b687-db98decf554a\"}\r\n",
      "{\"example\": \"I want to travel to Germany next year.\", \"id\": \"10ea7768-9117-4dfd-a2d6-09b0b6153f7c\"}\r\n",
      "{\"example\": \"I want to travel to Somalia next year.\", \"id\": \"71446b3a-41cc-474c-a92a-19f47d0535e7\"}\r\n",
      "{\"example\": \"I want to travel to Ukraine next year.\", \"id\": \"be397617-75e8-4837-bea5-31a190779c3c\"}\r\n",
      "{\"example\": \"I want to travel to Cape Verde next year.\", \"id\": \"8576db91-77e6-4aa8-9125-e3654e8315a8\"}\r\n",
      "{\"example\": \"I want to travel to Tajikistan next year.\", \"id\": \"be1a3553-4b34-4f9e-9e11-db72a68a00c1\"}\r\n",
      "{\"example\": \"I want to travel to Cambodia next year.\", \"id\": \"288a0f4f-6515-440d-899b-e49ff934a377\"}\r\n",
      "{\"example\": \"I want to travel to Latvia next year.\", \"id\": \"0aab03b8-24a7-4c10-9e1e-e8bedebc7647\"}\r\n",
      "{\"example\": \"I want to travel to Ghana next year.\", \"id\": \"a8f3788b-d7fe-4f7d-9000-f81c0534d7df\"}\r\n",
      "{\"example\": \"I want to travel to Antigua and Barbuda next year.\", \"id\": \"bdb0bc67-6436-4970-90a2-d767f005799d\"}\r\n",
      "{\"example\": \"Martha is my best friend.\", \"id\": \"08d6c072-e35d-4bb0-8b49-fdfa203af261\"}\r\n",
      "{\"example\": \"Florence is my best friend.\", \"id\": \"6d681466-2d93-4083-9172-f9b67c5e5b8c\"}\r\n",
      "{\"example\": \"Don is my best friend.\", \"id\": \"a3ef07ac-4693-4c0d-81f8-1cadd030f141\"}\r\n",
      "{\"example\": \"Steven is my best friend.\", \"id\": \"19d03937-624a-4081-b513-c3d16aefbbf6\"}\r\n",
      "{\"example\": \"Amy is my best friend.\", \"id\": \"47468e6e-4bd1-4ae8-af3a-68048d07d1a8\"}\r\n",
      "{\"example\": \"Ruth is my best friend.\", \"id\": \"f6f1038a-4f37-4dec-8167-3557ad29f8cd\"}\r\n",
      "{\"example\": \"Louise is my best friend.\", \"id\": \"7c0906e3-14ad-4088-91f0-7012362091d0\"}\r\n",
      "{\"example\": \"Katherine is my best friend.\", \"id\": \"83bf7dc2-96c3-4b6b-8e41-3730b7bac436\"}\r\n",
      "{\"example\": \"Elizabeth is my best friend.\", \"id\": \"07ce5bc4-0190-4b47-bb84-0798895dc915\"}\r\n",
      "{\"example\": \"Bob is my best friend.\", \"id\": \"817855ab-4811-4b8b-b540-7a86fa8c8cc4\"}"
     ]
    }
   ],
   "source": [
    "cat 'same_token_suite.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problems with this:\n",
    "# Not compatible across python versions (need to be careful when sharing)\n",
    "suite.save('same_token_suite_save.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next token invariant MFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_token(tokenizer, model, prompt, top_k=5, device='cuda'):\n",
    "    prompt = prompt.strip()\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    input_tokenized_length = input_ids.size(1)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids, \n",
    "        max_length=(input_tokenized_length + 1), \n",
    "        num_beams=top_k, \n",
    "        num_return_sequences=top_k, \n",
    "        early_stopping=True,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True\n",
    "    )\n",
    "\n",
    "    sequence_probabilities = F.softmax(beam_outputs.sequences_scores, dim=0)\n",
    "    \n",
    "    token_scores = []\n",
    "    for i, beam_output in enumerate(beam_outputs.sequences):\n",
    "        sequence_score = sequence_probabilities[i].item()\n",
    "        decoded_sequence = tokenizer.decode(beam_output, skip_special_tokens=True)\n",
    "        new_token = decoded_sequence[len(prompt):]\n",
    "        token_scores.append((new_token, sequence_score))\n",
    "    \n",
    "    return token_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_token(tokenizer, model, \"John works as a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = editor.template('The state of {state} is located in the United ', state=['Delaware', 'Tennessee', 'Georgia', 'Washington', 'Oregon', 'California', 'New Mexico', 'Alaska', 'Hawaii', 'Colorado'])\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompts.data[0])\n",
    "predict_next_token(tokenizer, model, prompts.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(inputs):\n",
    "    responses = []\n",
    "    confidences = []\n",
    "    for prompt in inputs:\n",
    "        predictions = predict_next_token(tokenizer, model, prompt, device='cuda')\n",
    "        next_tokens = []\n",
    "        token_confidences = []\n",
    "        for pred in predictions:\n",
    "            next_tokens.append(pred[0])\n",
    "            token_confidences.append(pred[1])\n",
    "        responses.append(next_tokens)\n",
    "        confidences.append(token_confidences)\n",
    "    return (responses, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expect_fn():\n",
    "    def e_fn(x, pred, conf, label=None, meta=None, run_idxs=None):\n",
    "        seen_tokens = set()\n",
    "        results = []\n",
    "        for p in pred:\n",
    "            for token in p:\n",
    "                seen_tokens.add(token)\n",
    "        for p in pred:\n",
    "            example_tokens = set()\n",
    "            for token in p:\n",
    "                example_tokens.add(token)\n",
    "            results.append([example_tokens == seen_tokens])\n",
    "        return results\n",
    "    return Expect.test(e_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect = make_expect_fn()\n",
    "next_token_test = MFT(**prompts, name='Next token invariant', description='The next predicted token is invariant for each prompt', expect=expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_test.run(generate_test_predictions, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
