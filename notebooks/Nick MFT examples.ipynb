{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import pandas as pd\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.expect import Expect\n",
    "from checklist.test_types import MFT\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFTs: Introduction\n",
    "In this notebook, we will create Minimum Functionality Tests (MFTs) for a generative language model. MFTs test one specific function of a language model. They are analogous to unit tests in traditional software engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup generative model\n",
    "Before we can test anything, we need to set up our language model. We will use the HuggingFace transformers library to load a GPT2 model.\n",
    "\n",
    "First, we create a tokenizer. The tokenizer is responsible for splitting strings into individual words, then converting those words into vectors of numbers that our model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8496, 754, 1242, 14210, 43989, 30]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Demonstrate what the tokenizer does\n",
    "tokenizer.encode(\"Wherefore art thou Romeo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tokenizer has turned the human-readable text into a list of numbers that the model understands. Next, let's load the GPT2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating text with the model requires a bit of work. Let's write a function `generate_sentence` to handle the text generation.\n",
    "\n",
    "`generate_sentence` has 3 mandatory parameters: \n",
    "- A tokenizer `tok`\n",
    "- A model `mdl`\n",
    "- A prompt `prompt`\n",
    "\n",
    "The prompt is a string that the model will use as a starting point for generating new text. It gives the model context about what kind of text should be generated.\n",
    "\n",
    "`generate_sentence` will output the generated text, as well as the model's raw scores for each predicted token. The scores will be useful later on for the MFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(tok, mdl, prompt, max_length=150, device='cuda') -> str:\n",
    "    tok_tensor = tok.encode(prompt, return_tensors='pt').to(device) # return_tensors = \"pt\" returns a PyTorch tensor\n",
    "    mdl.eval()\n",
    "    mdl.to(device)\n",
    "    out = mdl.generate(tok_tensor, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, early_stopping=True, output_scores=True, return_dict_in_generate=True)\n",
    "    text = tok.decode(out.sequences[0], skip_special_tokens=True)\n",
    "    scores = out.scores[0]\n",
    "    return {\"text\": text, \"scores\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Wherefore art thou Romeo?\\n\\nThou art Romeo, and thou art not Romeo.\\n\\n\\nAnd now, then, I say unto thee, thou wilt not be Romeo; but thou shalt be a man of God; and I will make thee a king of the world. And now I tell thee that I am the Lord of all things, that thou mayest reign in heaven and in earth, for ever and ever. Amen.',\n",
       " 'scores': tensor([[-8.4136e+00, -8.9426e+00, -1.3182e+01,  ..., -1.5396e+01,\n",
       "          -1.2783e+01, -7.7030e+00],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09],\n",
       "         [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "          -1.0000e+09, -1.0000e+09]], device='cuda:0')}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sentence(tokenizer, model, \"Wherefore art thou Romeo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is ready, we can write our first MFT.\n",
    "\n",
    "## MFT - Language prompt\n",
    "For this MFT, we will expect the model to create a reasonable continuation of a prompt. The model will be prompted with strings like \"In {country} the most commonly spoken language is \" where {country} is a placeholder for a country such as Spain.\n",
    "\n",
    "We will consider the MFT to pass if the model's output contains any language. This will demonstrate that the model understands the general context of the prompt. The mentioned language doesn't have to be accurate - for example, \"In Spain the most commonly spoken language is Indonesian\" would pass our test, because Indonesian is a language. The language may also be located anywhere in the output - for example, \"In Spain the most commonly spoken language is not easy to learn. Spanish has many complicated conjugations.\" would also pass our test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handwritten MFT\n",
    "First, we will write the MFT by hand. Then, we'll use Checklist's MFT class to demonstrate how Checklist helps us create the MFT much more quickly.\n",
    "\n",
    "#### Generate prompts from template\n",
    "We will use Checklist's Editor class to quickly create the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In China the most commonly spoken language is ',\n",
       " 'In India the most commonly spoken language is ',\n",
       " 'In United States the most commonly spoken language is ',\n",
       " 'In Indonesia the most commonly spoken language is ',\n",
       " 'In Brazil the most commonly spoken language is ',\n",
       " 'In Pakistan the most commonly spoken language is ',\n",
       " 'In Nigeria the most commonly spoken language is ',\n",
       " 'In Bangladesh the most commonly spoken language is ',\n",
       " 'In Russia the most commonly spoken language is ',\n",
       " 'In Mexico the most commonly spoken language is ']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = Editor()\n",
    "prompt_strs = editor.template(\"In {country} the most commonly spoken language is \")\n",
    "prompt_strs.data = prompt_strs.data[0:10]\n",
    "prompt_strs.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language CSV\n",
    "We need a list of languages to check if the model's output contains a language. To save some time, we will read language names from a CSV file. The data comes from standard ISO Language Codes https://datahub.io/core/language-codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha2</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>Afar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "      <td>Abkhazian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae</td>\n",
       "      <td>Avestan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ak</td>\n",
       "      <td>Akan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>yi</td>\n",
       "      <td>Yiddish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>yo</td>\n",
       "      <td>Yoruba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>za</td>\n",
       "      <td>Zhuang; Chuang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>zh</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>zu</td>\n",
       "      <td>Zulu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha2         English\n",
       "0       aa            Afar\n",
       "1       ab       Abkhazian\n",
       "2       ae         Avestan\n",
       "3       af       Afrikaans\n",
       "4       ak            Akan\n",
       "..     ...             ...\n",
       "179     yi         Yiddish\n",
       "180     yo          Yoruba\n",
       "181     za  Zhuang; Chuang\n",
       "182     zh         Chinese\n",
       "183     zu            Zulu\n",
       "\n",
       "[184 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://datahub.io/core/language-codes/r/language-codes.csv', 'language-codes.csv')\n",
    "lang_codes_csv = pd.read_csv('language-codes.csv')\n",
    "lang_codes_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the MFT\n",
    "Now we're ready to create the MFT. We will create 3 Pandas dataframes, one each for prompts, responses, and results. Then, we will loop over the prompts, send each prompt to the model, and determine if it passes or fails the test. Each prompt and its test result will be recorded in the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pd.DataFrame({\"id\": [], \"prompt\": []})\n",
    "responses = pd.DataFrame({\"id\": [], \"response\": []})\n",
    "results = pd.DataFrame({\"id\": [], \"p/f\": []})\n",
    "langs = lang_codes_csv[\"English\"].tolist()\n",
    "\n",
    "for (i, s) in enumerate(prompt_strs.data):\n",
    "    res = generate_sentence(tokenizer, model, s, device='cuda')\n",
    "    model_response = res[\"text\"][len(s):]\n",
    "    pf = 'fail'\n",
    "    \n",
    "    # Check if any language from the CSV data is in the generated string\n",
    "    for l in langs:\n",
    "        if l in model_response:\n",
    "            pf = 'pass'\n",
    "            break\n",
    "\n",
    "    prompts = prompts.append({\"id\": i, \"prompt\": s}, ignore_index=True)\n",
    "    responses = responses.append({\"id\": i, \"response\": model_response}, ignore_index=True)\n",
    "    results = results.append({\"id\": i, \"p/f\": pf}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show test results\n",
    "Now let's look at the results of our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>In China the most commonly spoken language is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>In India the most commonly spoken language is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>In United States the most commonly spoken lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>In Indonesia the most commonly spoken language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>In Brazil the most commonly spoken language is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>In Pakistan the most commonly spoken language is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>In Nigeria the most commonly spoken language is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>In Bangladesh the most commonly spoken languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>In Russia the most commonly spoken language is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>In Mexico the most commonly spoken language is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             prompt\n",
       "0  0.0     In China the most commonly spoken language is \n",
       "1  1.0     In India the most commonly spoken language is \n",
       "2  2.0  In United States the most commonly spoken lang...\n",
       "3  3.0  In Indonesia the most commonly spoken language...\n",
       "4  4.0    In Brazil the most commonly spoken language is \n",
       "5  5.0  In Pakistan the most commonly spoken language is \n",
       "6  6.0   In Nigeria the most commonly spoken language is \n",
       "7  7.0  In Bangladesh the most commonly spoken languag...\n",
       "8  8.0    In Russia the most commonly spoken language is \n",
       "9  9.0    In Mexico the most commonly spoken language is "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>한국어 (가지는), followed by 그리 (하고) and 현에 (아로).\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>vernacular Hindi, followed by Tamil, Bengali, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>한국어 (하기), followed by 고지 (가요).\\n\\nIn other wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>한국어 (하기요), followed by 가장 (고지).\\n\\nIn the Unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>한국어, which is used to describe the state of af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>vernacular English, which is also spoken in ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>한국어 (하기에서 모습니다).\\n\\nIn the United States, Engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>vernacular Bengali.\\n\\nBengali is the second m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>русский стразывация в польшение на что обреган...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>русский.\\n\\nIn the United States, there are se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           response\n",
       "0  0.0  한국어 (가지는), followed by 그리 (하고) and 현에 (아로).\\n\\...\n",
       "1  1.0  vernacular Hindi, followed by Tamil, Bengali, ...\n",
       "2  2.0  한국어 (하기), followed by 고지 (가요).\\n\\nIn other wor...\n",
       "3  3.0  한국어 (하기요), followed by 가장 (고지).\\n\\nIn the Unit...\n",
       "4  4.0  한국어, which is used to describe the state of af...\n",
       "5  5.0  vernacular English, which is also spoken in ma...\n",
       "6  6.0  한국어 (하기에서 모습니다).\\n\\nIn the United States, Engl...\n",
       "7  7.0  vernacular Bengali.\\n\\nBengali is the second m...\n",
       "8  8.0  русский стразывация в польшение на что обреган...\n",
       "9  9.0  русский.\\n\\nIn the United States, there are se..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>p/f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   p/f\n",
       "0  0.0  pass\n",
       "1  1.0  pass\n",
       "2  2.0  pass\n",
       "3  3.0  pass\n",
       "4  4.0  pass\n",
       "5  5.0  pass\n",
       "6  6.0  pass\n",
       "7  7.0  pass\n",
       "8  8.0  fail\n",
       "9  9.0  pass"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge all the dataframes to make the results easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>p/f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>In China the most commonly spoken language is</td>\n",
       "      <td>한국어 (가지는), followed by 그리 (하고) and 현에 (아로).\\n\\...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>In India the most commonly spoken language is</td>\n",
       "      <td>vernacular Hindi, followed by Tamil, Bengali, ...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>In United States the most commonly spoken lang...</td>\n",
       "      <td>한국어 (하기), followed by 고지 (가요).\\n\\nIn other wor...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>In Indonesia the most commonly spoken language...</td>\n",
       "      <td>한국어 (하기요), followed by 가장 (고지).\\n\\nIn the Unit...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>In Brazil the most commonly spoken language is</td>\n",
       "      <td>한국어, which is used to describe the state of af...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>In Pakistan the most commonly spoken language is</td>\n",
       "      <td>vernacular English, which is also spoken in ma...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>In Nigeria the most commonly spoken language is</td>\n",
       "      <td>한국어 (하기에서 모습니다).\\n\\nIn the United States, Engl...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>In Bangladesh the most commonly spoken languag...</td>\n",
       "      <td>vernacular Bengali.\\n\\nBengali is the second m...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>In Russia the most commonly spoken language is</td>\n",
       "      <td>русский стразывация в польшение на что обреган...</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>In Mexico the most commonly spoken language is</td>\n",
       "      <td>русский.\\n\\nIn the United States, there are se...</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             prompt  \\\n",
       "0  0.0     In China the most commonly spoken language is    \n",
       "1  1.0     In India the most commonly spoken language is    \n",
       "2  2.0  In United States the most commonly spoken lang...   \n",
       "3  3.0  In Indonesia the most commonly spoken language...   \n",
       "4  4.0    In Brazil the most commonly spoken language is    \n",
       "5  5.0  In Pakistan the most commonly spoken language is    \n",
       "6  6.0   In Nigeria the most commonly spoken language is    \n",
       "7  7.0  In Bangladesh the most commonly spoken languag...   \n",
       "8  8.0    In Russia the most commonly spoken language is    \n",
       "9  9.0    In Mexico the most commonly spoken language is    \n",
       "\n",
       "                                            response   p/f  \n",
       "0  한국어 (가지는), followed by 그리 (하고) and 현에 (아로).\\n\\...  pass  \n",
       "1  vernacular Hindi, followed by Tamil, Bengali, ...  pass  \n",
       "2  한국어 (하기), followed by 고지 (가요).\\n\\nIn other wor...  pass  \n",
       "3  한국어 (하기요), followed by 가장 (고지).\\n\\nIn the Unit...  pass  \n",
       "4  한국어, which is used to describe the state of af...  pass  \n",
       "5  vernacular English, which is also spoken in ma...  pass  \n",
       "6  한국어 (하기에서 모습니다).\\n\\nIn the United States, Engl...  pass  \n",
       "7  vernacular Bengali.\\n\\nBengali is the second m...  pass  \n",
       "8  русский стразывация в польшение на что обреган...  fail  \n",
       "9  русский.\\n\\nIn the United States, there are se...  pass  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(responses, results, on=\"id\")\n",
    "merged = pd.merge(prompts, merged, on=\"id\")\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's display the failing tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>p/f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>In Russia the most commonly spoken language is</td>\n",
       "      <td>русский стразывация в польшение на что обреган...</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           prompt  \\\n",
       "8  8.0  In Russia the most commonly spoken language is    \n",
       "\n",
       "                                            response   p/f  \n",
       "8  русский стразывация в польшение на что обреган...  fail  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.loc[merged['p/f'] == 'fail']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try running the MFT with Checklist. We will no longer need to keep track of results in Pandas dataframes, since Checklist will track the results for us.\n",
    "\n",
    "#### Create the expectation function\n",
    "In order to determine if an example passes or fails the test, Checklist uses an expectation function. An expectation function is a function that receives the example, then returns true if the example passes the test, or false if the example fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_language(x, pred, conf, label=None, meta=None):\n",
    "    for l in langs:\n",
    "        if l in pred:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_fn = Expect.single(contains_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can feed our prompts and expectation function into the MFT constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MFT(**prompt_strs, name='Language in response', description='The response contains a language.', expect=expect_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the test, Checklist also needs a function that generates the model's predictions for the inputs. The function receives all inputs (prompts) as a list, and must return the results in a tuple `(model_predictions, confidences)`, where `model_predictions` is a list of all the predictions, and `confidences` is a list of the model's scores for those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(inputs):\n",
    "    responses = []\n",
    "    confidences = []\n",
    "    for x in inputs:\n",
    "        res = generate_sentence(tokenizer, model, x, device='cuda')\n",
    "        model_response = res[\"text\"][len(x):]\n",
    "        responses.append(model_response)\n",
    "        confidences.append(res[\"scores\"])\n",
    "    return (responses, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['한국어, which is used to describe the state of affairs in the country.\\n\\nIn the United States, there are many different dialects of English, including English-speaking languages such as Spanish, French, German, Italian, Japanese, Korean, and Vietnamese.'],\n",
       " [tensor([[-1.1706e+01, -1.2572e+01, -1.4455e+01,  ..., -2.1273e+01,\n",
       "           -2.1612e+01, -1.6069e+01],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09],\n",
       "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
       "           -1.0000e+09, -1.0000e+09]], device='cuda:0')])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_responses([\"In Brazil the most commonly spoken language is \"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to run the test. The first argument to the `test.run()` function is the generator function we just created. We will also set the optional parameter `overwrite=True` so the test can be re-run without an error. If overwrite=False, then Checklist will reject subsequent test runs to prevent you from accidentally overwriting your test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n"
     ]
    }
   ],
   "source": [
    "test.run(generate_responses, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the results, we can use the `summary` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      10\n",
      "Fails (rate):    1 (10.0%)\n",
      "\n",
      "Example fails:\n",
      "русский стразывация в польшение на что обреганных и кормать.\n",
      "\n",
      "Продевительного таковы дляжется, можнощию задали былекти. Навроись � In Russia the most commonly spoken language is \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test results can also be explored visually by using the `visual_summary` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5b0b794bbb4201b7b0923bb63f19c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TestSummarizer(stats={'npassed': 9, 'nfailed': 1, 'nfiltered': 0}, summarizer={'name': 'Language in response',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.visual_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFT - Animal names prompt\n",
    "Let's make another MFT using the prompt \"The {animal} is running in the zoo.\" We will test if the model's response contains the same animal mentioned in the prompt. For example, for the prompt \"The goat is running in the zoo,\" a passing response would be something like, \"I have never seen a goat running before,\" because the word *goat* is mentioned in the response.\n",
    "\n",
    "This MFT has a small complication compared to the previous MFT. In this MFT, we need to check if the response mentions the same animal as the prompt. In order to do that, we need to associate the animal in the prompt with the animal in the response. We will see how Checklist can help us do this by storing metadata for each test case.\n",
    "\n",
    "### Handwritten test\n",
    "As before, let's first write the test without using Checklist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompts = pd.DataFrame({\"id\": [], \"prompt\": []})\n",
    "responses = pd.DataFrame({\"id\": [], \"response\": []})\n",
    "test_results = pd.DataFrame({\"id\": [], \"p/f\": []})\n",
    "\n",
    "animals = [\"dog\", \"cat\", \"giraffe\", \"aardvark\"]\n",
    "\n",
    "for (i, animal) in enumerate(animals):\n",
    "    prompt = f\"The {animal} is running in the zoo\"\n",
    "    res = generate_sentence(tokenizer, model, prompt, device='cuda')\n",
    "    pf = 'fail'\n",
    "    model_response = res[\"text\"][len(prompt):]\n",
    "    \n",
    "    # Check if the same animal is mentioned in the response\n",
    "    if animal in model_response:\n",
    "        pf = 'pass'\n",
    "\n",
    "    prompts = prompts.append({\"id\": i, \"prompt\": prompt}, ignore_index=True)\n",
    "    responses = responses.append({\"id\": i, \"response\": model_response}, ignore_index=True)\n",
    "    test_results = test_results.append({\"id\": i, \"p/f\": pf}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show test results\n",
    "Let's look at our test results. The first dataframe contains the prompts given to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>The dog is running in the zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The cat is running in the zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>The giraffe is running in the zoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>The aardvark is running in the zoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                              prompt\n",
       "0  0.0       The dog is running in the zoo\n",
       "1  1.0       The cat is running in the zoo\n",
       "2  2.0   The giraffe is running in the zoo\n",
       "3  3.0  The aardvark is running in the zoo"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next dataframe shows the model's response to the prompt (not including the prompt itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>.\\n\\n\"It's been a long time since I've seen a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>.\\n\\n\"I don't know what's going on,\" he said. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>.\\n\\n\"It's been a long time coming, but it's f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>.\\n\\n\"It's been a long time coming,\" he said. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           response\n",
       "0  0.0  .\\n\\n\"It's been a long time since I've seen a ...\n",
       "1  1.0  .\\n\\n\"I don't know what's going on,\" he said. ...\n",
       "2  2.0  .\\n\\n\"It's been a long time coming, but it's f...\n",
       "3  3.0  .\\n\\n\"It's been a long time coming,\" he said. ..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo: Make pandas print the whole response\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final dataframe shows the pass/fail status of the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>p/f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   p/f\n",
       "0  0.0  pass\n",
       "1  1.0  fail\n",
       "2  2.0  fail\n",
       "3  3.0  fail"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Checklist\n",
    "Now let's do the same test using Checklist. First, we will generate the prompts. This time, we will use the optional argument `meta=True` in the `editor.template()` function. This will cause Checklist to store the string substituted into the template so that it can be checked in the expectation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dog is running in the zoo',\n",
       " 'The cat is running in the zoo',\n",
       " 'The giraffe is running in the zoo',\n",
       " 'The aardvark is running in the zoo']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal_prompts = editor.template(\"The {animal} is running in the zoo\", animal=[\"dog\", \"cat\", \"giraffe\", \"aardvark\"], meta=True)\n",
    "animal_prompts.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeing the metadata\n",
    "Let's take a peek at the metadata stored with the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'animal': 'dog'},\n",
       " {'animal': 'cat'},\n",
       " {'animal': 'giraffe'},\n",
       " {'animal': 'aardvark'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal_prompts.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing metadata in the expectation function\n",
    "Checklist will use the optional `meta` parameter to send the metadata to the expectation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_same_animal(x, pred, conf, label=None, meta=None):\n",
    "    return meta['animal'] in pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_fn = Expect.single(contains_same_animal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the test\n",
    "Now we're ready to run the test. We can reuse the `generate_responses()` function that we wrote at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MFT(**animal_prompts, name='Same animal in response', description='The response contains the same animal mentioned in the prompt.', expect=expect_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 4 examples\n"
     ]
    }
   ],
   "source": [
    "test.run(generate_responses, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      4\n",
      "Fails (rate):    3 (75.0%)\n",
      "\n",
      "Example fails:\n",
      ".\n",
      "\n",
      "\"It's been a long time coming, but it's finally here,\" he said. The giraffe is running in the zoo\n",
      "----\n",
      ".\n",
      "\n",
      "\"I don't know what's going on,\" he said. \"I've never seen anything like this before.\" The cat is running in the zoo\n",
      "----\n",
      ".\n",
      "\n",
      "\"It's been a long time coming,\" he said. \"I've never seen anything like it before.\" The aardvark is running in the zoo\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d648086d8438487b981c04c066ff859f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TestSummarizer(stats={'npassed': 1, 'nfailed': 3, 'nfiltered': 0}, summarizer={'name': 'Same animal in respons…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.visual_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
